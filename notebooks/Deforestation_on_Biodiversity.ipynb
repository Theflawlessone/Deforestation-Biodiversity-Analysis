{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Theflawlessone/Deforestation-Biodiversity-Analysis/blob/main/notebooks/Deforestation_on_Biodiversity.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7c1996b0",
      "metadata": {
        "id": "7c1996b0"
      },
      "source": [
        "\n",
        "# Project Overview\n",
        "**Link to Google drive to access datasets:** https://drive.google.com/drive/folders/1c84LaLj2T4c4EN0RzQPdmtAh3UoFJjux?usp=sharing  \n",
        "<br>**Notes when running project**\n",
        "- We formatted it so you can use the table of contents easily we have main sections labeled below\n",
        "- Sometimes runs will get stuck on the line \"test for species_richness compared to estimate in merged dataset\" in the \"mann-whitney u testing\", not sure why but just go to \"preprocessing & cleaning\" and then under \"creating/editing new datafames\" its labeled \"create new columns: species_richness and te_count_species\" rerun that snippet and it will work that second time! <br>\n",
        "\n",
        "**Table of Contents:**\n",
        "- Loading Datasets\n",
        "- Preprocessing & Cleaning\n",
        "- Exploratory Data Analysis (EDA)\n",
        "- Statistical Analysis\n",
        "- Models\n",
        "\n",
        "**Summary of Datasets/Column Names**\n",
        "This is the biodiversity kaggle dataset, there is a parks.csv and species.csv: https://www.kaggle.com/datasets/nationalparkservice/park-biodiversity\n",
        "Columns/Rows:\n",
        "  <br>> **For parks.csv:**\n",
        "- Park Code,\n",
        "- Park Name,\n",
        "- State,\n",
        "- Acres,\n",
        "- Latitude,\n",
        "- Longitude\n",
        "<br>> **For species.csv**\n",
        "- Species id,\n",
        "- Park name,\n",
        "- Category (mammal, bird, etc),\n",
        "- Order (scientific order specialty),\n",
        "- Family,\n",
        "- Scientific Name,\n",
        "- Common name,\n",
        "- Record status,\n",
        "- Occurrence,\n",
        "- Nativeness,\n",
        "- Abundance,\n",
        "- Seasonality,\n",
        "- Conservation status.\n",
        "We also add species_richness (count of native species per state) and count_te_species (count of threatened/endangered species) early on.\n",
        "\n",
        "This is the deforestation dataset we found: https://research.fs.usda.gov/programs/fia?utm_source=#data-and-tools\n",
        "it looks at different states over different years (total just means all inventory years combined),\n",
        "then 'estimate' is the forest area change for that state/year in acres\n",
        "next is 'variance' which is the squared standard error (smaller number means more confidence)\n",
        "next is 'plot_count' which is the number of sample plots used (so bigger number would be better here)\n",
        "then se is standard error estimate and percentage just helps you find that actual se amount in acres.\n",
        "\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "db770552",
      "metadata": {
        "id": "db770552"
      },
      "source": [
        "# Data Loading\n",
        "\n",
        "Cells related to loading datasets (paths preserved)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "TFnzrjoJLsnv",
      "metadata": {
        "id": "TFnzrjoJLsnv"
      },
      "source": [
        "##Loading datsets"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "QNquenJEPX5o",
      "metadata": {
        "id": "QNquenJEPX5o"
      },
      "source": [
        "###Importing nessecary libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cC26AV3avmji",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cC26AV3avmji",
        "outputId": "786bef60-9b14-4d1e-92bf-4ea4883722f5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pingouin in /usr/local/lib/python3.12/dist-packages (0.5.5)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from pingouin) (3.10.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from pingouin) (2.0.2)\n",
            "Requirement already satisfied: pandas>=1.5 in /usr/local/lib/python3.12/dist-packages (from pingouin) (2.2.2)\n",
            "Requirement already satisfied: pandas-flavor in /usr/local/lib/python3.12/dist-packages (from pingouin) (0.7.0)\n",
            "Requirement already satisfied: scikit-learn>=1.2 in /usr/local/lib/python3.12/dist-packages (from pingouin) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from pingouin) (1.16.3)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.12/dist-packages (from pingouin) (0.13.2)\n",
            "Requirement already satisfied: statsmodels in /usr/local/lib/python3.12/dist-packages (from pingouin) (0.14.5)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.12/dist-packages (from pingouin) (0.9.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.5->pingouin) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.5->pingouin) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.5->pingouin) (2025.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=1.2->pingouin) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=1.2->pingouin) (3.6.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->pingouin) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->pingouin) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->pingouin) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->pingouin) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->pingouin) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib->pingouin) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->pingouin) (3.2.5)\n",
            "Requirement already satisfied: xarray in /usr/local/lib/python3.12/dist-packages (from pandas-flavor->pingouin) (2025.10.1)\n",
            "Requirement already satisfied: patsy>=0.5.6 in /usr/local/lib/python3.12/dist-packages (from statsmodels->pingouin) (1.0.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas>=1.5->pingouin) (1.17.0)\n",
            "Requirement already satisfied: fuzzywuzzy in /usr/local/lib/python3.12/dist-packages (0.18.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install pingouin\n",
        "!pip install fuzzywuzzy\n",
        "!pip install us"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "342fcf53",
      "metadata": {
        "id": "342fcf53"
      },
      "outputs": [],
      "source": [
        "# Consolidated imports (auto-extracted)\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import re\n",
        "import geopandas as gpd\n",
        "import seaborn as sns\n",
        "import folium\n",
        "import requests  #our initial map outline\n",
        "from IPython.display import display\n",
        "import numpy as np\n",
        "from scipy.stats import chi2_contingency\n",
        "from scipy.stats import mannwhitneyu\n",
        "from scipy.stats import ttest_ind\n",
        "from sklearn.utils import resample\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from imblearn.over_sampling import SMOTE\n",
        "import kagglehub\n",
        "import os, pandas as pd\n",
        "import pingouin\n",
        "import fuzzywuzzy\n",
        "import us\n",
        "\n",
        "\n",
        "\n",
        "# End of consolidated imports\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Ee1uzPGPLgOx",
      "metadata": {
        "id": "Ee1uzPGPLgOx"
      },
      "source": [
        "###loading datasets and assigning names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ee311c11",
      "metadata": {
        "id": "ee311c11"
      },
      "outputs": [],
      "source": [
        "!pip install gdown\n",
        "\n",
        "\n",
        "# download from drive\n",
        "!gdown 1g3IRypHA2EUwWaAkyD_-n7RzfLSJuXD5 -O parks.csv\n",
        "!gdown 1Ya4KF7cCkYF7uRs67VNnGpJillBhA8e1 -O species.csv\n",
        "!gdown 167-iGjrX0ox87N5eXVt-q_jzhtNsKQDY -O deforestation.csv\n",
        "\n",
        "# load\n",
        "parks = pd.read_csv(\"parks.csv\")\n",
        "species = pd.read_csv(\"species.csv\")\n",
        "deforestation = pd.read_csv(\"deforestation.csv\")\n",
        "\n",
        "print(\"Parks:\", parks.shape)\n",
        "print(\"Species:\", species.shape)\n",
        "print(\"Deforestation:\", deforestation.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "n9vjKMbJ2OpC",
      "metadata": {
        "id": "n9vjKMbJ2OpC"
      },
      "source": [
        "####weather dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0MNGpTYSpQJl",
      "metadata": {
        "id": "0MNGpTYSpQJl"
      },
      "outputs": [],
      "source": [
        "#weather dataset\n",
        "path = kagglehub.dataset_download(\"justinrwong/average-monthly-temperature-by-us-state\")\n",
        "\n",
        "# find CSV file inside the dataset folder\n",
        "for file in os.listdir(path):\n",
        "    if file.endswith(\".csv\"):\n",
        "        weather_path = os.path.join(path, file)\n",
        "        break\n",
        "\n",
        "weather = pd.read_csv(weather_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8ne9SGeJ1ti1",
      "metadata": {
        "id": "8ne9SGeJ1ti1"
      },
      "outputs": [],
      "source": [
        "#checking which states are in it, 48 states are in it not hawaii and alaska\n",
        "print(weather[weather[\"state\"].str.contains(\"Alaska\", case=False)])\n",
        "print(weather[weather[\"state\"].str.contains(\"Hawaii\", case=False)])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "CZkeXM0cZqRX",
      "metadata": {
        "id": "CZkeXM0cZqRX"
      },
      "source": [
        "###making sure import was successful"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6uZ0303KqMpt",
      "metadata": {
        "id": "6uZ0303KqMpt"
      },
      "outputs": [],
      "source": [
        "print(\"Weather:\", weather.head(10))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "IBuGEGhYZtna",
      "metadata": {
        "id": "IBuGEGhYZtna"
      },
      "outputs": [],
      "source": [
        "print(\"Parks:\", parks.head(10))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eTe_cUuVZwrR",
      "metadata": {
        "id": "eTe_cUuVZwrR"
      },
      "outputs": [],
      "source": [
        "print(\"Species:\", species.head(10))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ztO57IBlZypR",
      "metadata": {
        "id": "ztO57IBlZypR"
      },
      "outputs": [],
      "source": [
        "print(\"Deforestation:\", deforestation.head(10))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "HVN6myIeakfM",
      "metadata": {
        "id": "HVN6myIeakfM"
      },
      "source": [
        "###Check dataframe column datatypes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Mpt3RvzfsnLb",
      "metadata": {
        "id": "Mpt3RvzfsnLb"
      },
      "outputs": [],
      "source": [
        "# weather.columns\n",
        "# weather.dtypes\n",
        "\n",
        "# parks.columns\n",
        "# parks.dtypes\n",
        "\n",
        "# species.columns\n",
        "# species.dtypes\n",
        "\n",
        "# deforestation.columns\n",
        "# deforestation.dtypes"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "SFZ_CMlAmRxS",
      "metadata": {
        "id": "SFZ_CMlAmRxS"
      },
      "source": [
        "####%whos image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "DZU1uvNgmUz1",
      "metadata": {
        "id": "DZU1uvNgmUz1"
      },
      "outputs": [],
      "source": [
        "!gdown 11oNNQE956jKJnIV2CjFYteQ_uOB7dnDZ -O whos.pdf\n",
        "\n",
        "!apt-get install -y poppler-utils  # only needs to run once\n",
        "!pdftoppm whos.pdf whos -png\n",
        "\n",
        "from IPython.display import Image\n",
        "Image(\"whos-1.png\")  # first page as image\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2FchKCQtLKNJ",
      "metadata": {
        "id": "2FchKCQtLKNJ"
      },
      "source": [
        "### Mappings"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bUXO51qsaXEU",
      "metadata": {
        "id": "bUXO51qsaXEU"
      },
      "source": [
        "#### Through matplot lib\n",
        "<br>\n",
        "Code below does not work due to the lack of federal funds on the website it is using (it was working now it is not) <br>\n",
        "What is found when you go to the website: <br>\n",
        "  NOTICE:\n",
        "  Due to the lapse of federal funding, portions of this website will not be updated. Any inquiries submitted will not be answered until appropriations are enacted."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4f8ef471",
      "metadata": {
        "id": "4f8ef471"
      },
      "outputs": [],
      "source": [
        "# US Census Bureau states shapefile (1:20m scale, includes states)\n",
        "# url = \"https://www2.census.gov/geo/tiger/GENZ2022/shp/cb_2022_us_state_20m.zip\"\n",
        "\n",
        "# us_states = gpd.read_file(url)\n",
        "\n",
        "# Merge with species_summary\n",
        "# merged = us_states.merge(species_summary, left_on=\"NAME\", right_on=\"State_Name\", how=\"left\")\n",
        "\n",
        "# Plot\n",
        "# merged.plot(column=\"Species_richness\", cmap=\"viridis\", legend=True, figsize=(12,6))\n",
        "# plt.title(\"Species richness by State\")\n",
        "# plt.show("
      ]
    },
    {
      "cell_type": "markdown",
      "id": "-l6SFnndLaEQ",
      "metadata": {
        "id": "-l6SFnndLaEQ"
      },
      "source": [
        "####through Folium and requests"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d096b2da",
      "metadata": {
        "collapsed": true,
        "id": "d096b2da"
      },
      "outputs": [],
      "source": [
        "parks = pd.read_csv(\"parks.csv\")\n",
        "species = pd.read_csv(\"species.csv\")\n",
        "\n",
        "#merge species by park/state\n",
        "species_state = species.merge(parks[[\"Park Name\", \"State\"]], on=\"Park Name\", how=\"left\")\n",
        "\n",
        "#count unique species per state\n",
        "biodiversity_state = (\n",
        "    species_state.groupby(\"State\")[\"Scientific Name\"] #state is 2 letter abbreviation\n",
        "    .nunique()\n",
        "    .reset_index()\n",
        "    .rename(columns={\"Scientific Name\": \"Unique_Species\"})\n",
        ")\n",
        "\n",
        "# 3. Load US States GeoJSON\n",
        "url = \"https://raw.githubusercontent.com/python-visualization/folium/main/examples/data/us-states.json\"\n",
        "state_geo = requests.get(url).json()\n",
        "\n",
        "#map\n",
        "m = folium.Map(location=[40, -95], zoom_start=4)\n",
        "\n",
        "# Using Cloropleth\n",
        "folium.Choropleth(\n",
        "    geo_data=state_geo,\n",
        "    name=\"choropleth\",\n",
        "    data=biodiversity_state,      #species per state\n",
        "    columns=[\"State\", \"Unique_Species\"],\n",
        "    key_on=\"feature.id\",       #match state abbreviation w state on map\n",
        "    fill_color=\"YlGn\",       #yellow/green scale\n",
        "    fill_opacity=0.7,\n",
        "    line_opacity=0.2,\n",
        "    legend_name=\"Unique Species per State\"\n",
        ").add_to(m)\n",
        "\n",
        "#markers\n",
        "for _, row in parks.iterrows():\n",
        "    folium.Marker(\n",
        "        location=[row[\"Latitude\"], row[\"Longitude\"]],\n",
        "        popup=f\"<b>{row['Park Name']}</b><br>State: {row['State']}<br>Acres: {row['Acres']:,}\",  #to see park info\n",
        "        icon=folium.Icon(color=\"green\", icon=\"tree\", prefix=\"fa\")\n",
        "    ).add_to(m)\n",
        "\n",
        "#save\n",
        "m.save(\"biodiversity_map.html\")\n",
        "display(m)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "H7DHkGl8vvFi",
      "metadata": {
        "id": "H7DHkGl8vvFi"
      },
      "source": [
        "####average temp/year graph - 2019/2022"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "OOO_sdfTo_G9",
      "metadata": {
        "id": "OOO_sdfTo_G9"
      },
      "outputs": [],
      "source": [
        "# --- 1. Filter for year 2019 ---\n",
        "weather_2019 = weather[weather [\"year\"] == 2019]\n",
        "\n",
        "# --- 2. Compute average temperature per state ---\n",
        "temp_state = (\n",
        "    weather_2019.groupby(\"state\")[\"average_temp\"]\n",
        "    .mean()\n",
        "    .reset_index()\n",
        "    .rename(columns={\"state\": \"State\", \"average_temp\": \"Avg_Temperature\"})\n",
        ")\n",
        "\n",
        "# Optional: ensure state abbreviations\n",
        "if len(temp_state[\"State\"].iloc[0]) > 2:\n",
        "    temp_state[\"State\"] = temp_state[\"State\"].map(\n",
        "        lambda x: us.states.lookup(x).abbr if us.states.lookup(x) else None\n",
        "    )\n",
        "\n",
        "# --- 3. Load US States GeoJSON ---\n",
        "url = \"https://raw.githubusercontent.com/python-visualization/folium/main/examples/data/us-states.json\"\n",
        "state_geo = requests.get(url).json()\n",
        "\n",
        "# --- 4. Create Folium map ---\n",
        "m = folium.Map(location=[40, -95], zoom_start=4)\n",
        "\n",
        "# --- 5. Add Choropleth layer ---\n",
        "folium.Choropleth(\n",
        "    geo_data=state_geo,\n",
        "    name=\"choropleth\",\n",
        "    data=temp_state,\n",
        "    columns=[\"State\", \"Avg_Temperature\"],\n",
        "    key_on=\"feature.id\",\n",
        "    fill_color=\"YlOrRd\",\n",
        "    fill_opacity=0.7,\n",
        "    line_opacity=0.2,\n",
        "    legend_name=\"Average Temperature (°F) per State, 2019\"\n",
        ").add_to(m)\n",
        "\n",
        "# --- 6. Optional: Add markers ---\n",
        "for _, row in weather_2019.drop_duplicates(\"state\").iterrows():\n",
        "    folium.Marker(\n",
        "        location=[row[\"centroid_lat\"], row[\"centroid_lon\"]],\n",
        "        popup=f\"<b>{row['state']}</b><br>Avg Temp: {row['average_temp']:.1f}°F\",\n",
        "        icon=folium.Icon(color=\"red\", icon=\"thermometer-half\", prefix=\"fa\")\n",
        "    ).add_to(m)\n",
        "\n",
        "# --- 7. Save and show ---\n",
        "m.save(\"temperature_map_2019.html\")\n",
        "display(m)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "KiRvqJ3Wvcqd",
      "metadata": {
        "id": "KiRvqJ3Wvcqd"
      },
      "outputs": [],
      "source": [
        "# --- 1. Filter for year 2020 ---\n",
        "weather_2020 = weather[weather [\"year\"] == 2020]\n",
        "\n",
        "# --- 2. Compute average temperature per state ---\n",
        "temp_state = (\n",
        "    weather_2020.groupby(\"state\")[\"average_temp\"]\n",
        "    .mean()\n",
        "    .reset_index()\n",
        "    .rename(columns={\"state\": \"State\", \"average_temp\": \"Avg_Temperature\"})\n",
        ")\n",
        "\n",
        "# Optional: ensure state abbreviations\n",
        "if len(temp_state[\"State\"].iloc[0]) > 2:\n",
        "    temp_state[\"State\"] = temp_state[\"State\"].map(\n",
        "        lambda x: us.states.lookup(x).abbr if us.states.lookup(x) else None\n",
        "    )\n",
        "\n",
        "# --- 3. Load US States GeoJSON ---\n",
        "url = \"https://raw.githubusercontent.com/python-visualization/folium/main/examples/data/us-states.json\"\n",
        "state_geo = requests.get(url).json()\n",
        "\n",
        "# --- 4. Create Folium map ---\n",
        "m = folium.Map(location=[40, -95], zoom_start=4)\n",
        "\n",
        "# --- 5. Add Choropleth layer ---\n",
        "folium.Choropleth(\n",
        "    geo_data=state_geo,\n",
        "    name=\"choropleth\",\n",
        "    data=temp_state,\n",
        "    columns=[\"State\", \"Avg_Temperature\"],\n",
        "    key_on=\"feature.id\",\n",
        "    fill_color=\"YlOrRd\",\n",
        "    fill_opacity=0.7,\n",
        "    line_opacity=0.2,\n",
        "    legend_name=\"Average Temperature (°F) per State, 2020\"\n",
        ").add_to(m)\n",
        "\n",
        "# --- 6. Optional: Add markers ---\n",
        "for _, row in weather_2020.drop_duplicates(\"state\").iterrows():\n",
        "    folium.Marker(\n",
        "        location=[row[\"centroid_lat\"], row[\"centroid_lon\"]],\n",
        "        popup=f\"<b>{row['state']}</b><br>Avg Temp: {row['average_temp']:.1f}°F\",\n",
        "        icon=folium.Icon(color=\"red\", icon=\"thermometer-half\", prefix=\"fa\")\n",
        "    ).add_to(m)\n",
        "\n",
        "# --- 7. Save and show ---\n",
        "m.save(\"temperature_map_2020.html\")\n",
        "display(m)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "yLGRvhoZppeI",
      "metadata": {
        "id": "yLGRvhoZppeI"
      },
      "outputs": [],
      "source": [
        "# --- 1. Filter for year 2021 ---\n",
        "weather_2021 = weather[weather [\"year\"] == 2021]\n",
        "\n",
        "# --- 2. Compute average temperature per state ---\n",
        "temp_state = (\n",
        "    weather_2021.groupby(\"state\")[\"average_temp\"]\n",
        "    .mean()\n",
        "    .reset_index()\n",
        "    .rename(columns={\"state\": \"State\", \"average_temp\": \"Avg_Temperature\"})\n",
        ")\n",
        "\n",
        "# Optional: ensure state abbreviations\n",
        "if len(temp_state[\"State\"].iloc[0]) > 2:\n",
        "    temp_state[\"State\"] = temp_state[\"State\"].map(\n",
        "        lambda x: us.states.lookup(x).abbr if us.states.lookup(x) else None\n",
        "    )\n",
        "\n",
        "# --- 3. Load US States GeoJSON ---\n",
        "url = \"https://raw.githubusercontent.com/python-visualization/folium/main/examples/data/us-states.json\"\n",
        "state_geo = requests.get(url).json()\n",
        "\n",
        "# --- 4. Create Folium map ---\n",
        "m = folium.Map(location=[40, -95], zoom_start=4)\n",
        "\n",
        "# --- 5. Add Choropleth layer ---\n",
        "folium.Choropleth(\n",
        "    geo_data=state_geo,\n",
        "    name=\"choropleth\",\n",
        "    data=temp_state,\n",
        "    columns=[\"State\", \"Avg_Temperature\"],\n",
        "    key_on=\"feature.id\",\n",
        "    fill_color=\"YlOrRd\",\n",
        "    fill_opacity=0.7,\n",
        "    line_opacity=0.2,\n",
        "    legend_name=\"Average Temperature (°F) per State, 2021\"\n",
        ").add_to(m)\n",
        "\n",
        "# --- 6. Optional: Add markers ---\n",
        "for _, row in weather_2021.drop_duplicates(\"state\").iterrows():\n",
        "    folium.Marker(\n",
        "        location=[row[\"centroid_lat\"], row[\"centroid_lon\"]],\n",
        "        popup=f\"<b>{row['state']}</b><br>Avg Temp: {row['average_temp']:.1f}°F\",\n",
        "        icon=folium.Icon(color=\"red\", icon=\"thermometer-half\", prefix=\"fa\")\n",
        "    ).add_to(m)\n",
        "\n",
        "# --- 7. Save and show ---\n",
        "m.save(\"temperature_map_2021.html\")\n",
        "display(m)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "xwDf9cS7pq1o",
      "metadata": {
        "id": "xwDf9cS7pq1o"
      },
      "outputs": [],
      "source": [
        "# --- 1. Filter for year 2022 ---\n",
        "weather_2022 = weather[weather [\"year\"] == 2022]\n",
        "\n",
        "# --- 2. Compute average temperature per state ---\n",
        "temp_state = (\n",
        "    weather_2022.groupby(\"state\")[\"average_temp\"]\n",
        "    .mean()\n",
        "    .reset_index()\n",
        "    .rename(columns={\"state\": \"State\", \"average_temp\": \"Avg_Temperature\"})\n",
        ")\n",
        "\n",
        "# Optional: ensure state abbreviations\n",
        "if len(temp_state[\"State\"].iloc[0]) > 2:\n",
        "    temp_state[\"State\"] = temp_state[\"State\"].map(\n",
        "        lambda x: us.states.lookup(x).abbr if us.states.lookup(x) else None\n",
        "    )\n",
        "\n",
        "# --- 3. Load US States GeoJSON ---\n",
        "url = \"https://raw.githubusercontent.com/python-visualization/folium/main/examples/data/us-states.json\"\n",
        "state_geo = requests.get(url).json()\n",
        "\n",
        "# --- 4. Create Folium map ---\n",
        "m = folium.Map(location=[40, -95], zoom_start=4)\n",
        "\n",
        "# --- 5. Add Choropleth layer ---\n",
        "folium.Choropleth(\n",
        "    geo_data=state_geo,\n",
        "    name=\"choropleth\",\n",
        "    data=temp_state,\n",
        "    columns=[\"State\", \"Avg_Temperature\"],\n",
        "    key_on=\"feature.id\",\n",
        "    fill_color=\"YlOrRd\",\n",
        "    fill_opacity=0.7,\n",
        "    line_opacity=0.2,\n",
        "    legend_name=\"Average Temperature (°F) per State, 2022\"\n",
        ").add_to(m)\n",
        "\n",
        "# --- 6. Optional: Add markers ---\n",
        "for _, row in weather_2020.drop_duplicates(\"state\").iterrows():\n",
        "    folium.Marker(\n",
        "        location=[row[\"centroid_lat\"], row[\"centroid_lon\"]],\n",
        "        popup=f\"<b>{row['state']}</b><br>Avg Temp: {row['average_temp']:.1f}°F\",\n",
        "        icon=folium.Icon(color=\"red\", icon=\"thermometer-half\", prefix=\"fa\")\n",
        "    ).add_to(m)\n",
        "\n",
        "# --- 7. Save and show ---\n",
        "m.save(\"temperature_map_2022.html\")\n",
        "display(m)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "lIIfXVXPpSqh",
      "metadata": {
        "id": "lIIfXVXPpSqh"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import folium\n",
        "import requests\n",
        "import us\n",
        "from IPython.display import HTML\n",
        "\n",
        "# --- Helper Function ---\n",
        "def get_temp_data(weather, year):\n",
        "    df = weather[weather[\"year\"] == year]\n",
        "    temp_state = (\n",
        "        df.groupby(\"state\")[\"average_temp\"]\n",
        "        .mean()\n",
        "        .reset_index()\n",
        "        .rename(columns={\"state\": \"State\", \"average_temp\": \"Avg_Temperature\"})\n",
        "    )\n",
        "    if len(temp_state[\"State\"].iloc[0]) > 2:\n",
        "        temp_state[\"State\"] = temp_state[\"State\"].map(\n",
        "            lambda x: us.states.lookup(x).abbr if us.states.lookup(x) else None\n",
        "        )\n",
        "    return temp_state\n",
        "\n",
        "# --- Load GeoJSON ---\n",
        "url = \"https://raw.githubusercontent.com/python-visualization/folium/main/examples/data/us-states.json\"\n",
        "state_geo = requests.get(url).json()\n",
        "\n",
        "# --- Generate maps for each year ---\n",
        "maps = {}\n",
        "for year in [2019, 2020, 2021, 2022]:\n",
        "    temp_state = get_temp_data(weather, year)\n",
        "    m = folium.Map(location=[37.8, -96], zoom_start=4)\n",
        "    folium.Choropleth(\n",
        "        geo_data=state_geo,\n",
        "        data=temp_state,\n",
        "        columns=[\"State\", \"Avg_Temperature\"],\n",
        "        key_on=\"feature.id\",\n",
        "        fill_color=\"YlOrRd\",\n",
        "        fill_opacity=0.8,\n",
        "        line_opacity=0.3,\n",
        "        legend_name=f\"Average Temperature (°F) - {year}\"\n",
        "    ).add_to(m)\n",
        "    maps[year] = m._repr_html_()  # store HTML representation\n",
        "\n",
        "# --- Combine all four maps into a single HTML grid ---\n",
        "html = f\"\"\"\n",
        "<h2 style=\"text-align:center;\">Average State Temperature (°F) per Year</h2>\n",
        "<div style=\"display:grid; grid-template-columns: 1fr 1fr; gap:10px;\">\n",
        "  <div>{maps[2019]}</div>\n",
        "  <div>{maps[2020]}</div>\n",
        "  <div>{maps[2021]}</div>\n",
        "  <div>{maps[2022]}</div>\n",
        "</div>\n",
        "\"\"\"\n",
        "\n",
        "# --- Save combined HTML file ---\n",
        "with open(\"temperature_maps_2019_2022.html\", \"w\") as f:\n",
        "    f.write(html)\n",
        "\n",
        "# --- Display in Jupyter Notebook ---\n",
        "HTML(html)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0LxR8wrAsiJr",
      "metadata": {
        "id": "0LxR8wrAsiJr"
      },
      "source": [
        "#####seasonal temps 2019/2022"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import folium\n",
        "import requests\n",
        "import us\n",
        "from IPython.display import HTML\n",
        "\n",
        "# --- 1. Define Seasons ---\n",
        "def get_season(month):\n",
        "    if month in [3, 4, 5]:\n",
        "        return \"Spring\"\n",
        "    elif month in [6, 7, 8]:\n",
        "        return \"Summer\"\n",
        "    elif month in [9, 10, 11]:\n",
        "        return \"Autumn\"\n",
        "    else:\n",
        "        return \"Winter\"\n",
        "\n",
        "# --- 2. Filter for Year 2019 ---\n",
        "weather_2019 = weather[weather[\"year\"] == 2019].copy()\n",
        "\n",
        "# Check if any data exists\n",
        "if weather_2019.empty:\n",
        "    raise ValueError(\"No weather data available for 2019.\")\n",
        "\n",
        "weather_2019[\"Season\"] = weather_2019[\"month\"].apply(get_season)\n",
        "\n",
        "# --- 3. Compute Average Temperature per State per Season ---\n",
        "seasonal_temps = (\n",
        "    weather_2019.groupby([\"state\", \"Season\"])[\"average_temp\"]\n",
        "    .mean()\n",
        "    .reset_index()\n",
        "    .rename(columns={\"state\": \"State\", \"average_temp\": \"Avg_Temperature\"})\n",
        ")\n",
        "\n",
        "# --- 4. Ensure State Abbreviations (for GeoJSON matching) ---\n",
        "if not seasonal_temps.empty and len(seasonal_temps[\"State\"].iloc[0]) > 2:\n",
        "    seasonal_temps[\"State\"] = seasonal_temps[\"State\"].map(\n",
        "        lambda x: us.states.lookup(x).abbr if us.states.lookup(x) else None\n",
        "    )\n",
        "\n",
        "# Drop any rows where the state abbreviation couldn't be found\n",
        "seasonal_temps.dropna(subset=[\"State\"], inplace=True)\n",
        "\n",
        "# --- 5. Load US States GeoJSON ---\n",
        "url = \"https://raw.githubusercontent.com/python-visualization/folium/main/examples/data/us-states.json\"\n",
        "state_geo = requests.get(url).json()\n",
        "\n",
        "# --- 6. Helper Function to Create Seasonal Map ---\n",
        "def make_map(df, season):\n",
        "    temp_state = df[df[\"Season\"] == season]\n",
        "    m = folium.Map(location=[37.8, -96], zoom_start=4)\n",
        "    folium.Choropleth(\n",
        "        geo_data=state_geo,\n",
        "        data=temp_state,\n",
        "        columns=[\"State\", \"Avg_Temperature\"],\n",
        "        key_on=\"feature.id\",\n",
        "        fill_color=\"YlOrRd\",\n",
        "        fill_opacity=0.8,\n",
        "        line_opacity=0.3,\n",
        "        legend_name=f\"Average Temperature (°F) - {season} 2019\"\n",
        "    ).add_to(m)\n",
        "    return m._repr_html_()\n",
        "\n",
        "# --- 7. Create Maps for All Seasons ---\n",
        "maps = {}\n",
        "for season in [\"Spring\", \"Summer\", \"Autumn\", \"Winter\"]:\n",
        "    maps[season] = make_map(seasonal_temps, season)\n",
        "\n",
        "# --- 8. Combine into One HTML Dashboard ---\n",
        "html = f\"\"\"\n",
        "<h2 style=\"text-align:center;\">Average State Temperature (°F) by Season - 2019</h2>\n",
        "<div style=\"display:grid; grid-template-columns: 1fr 1fr; gap:10px;\">\n",
        "  <div>{maps['Spring']}</div>\n",
        "  <div>{maps['Summer']}</div>\n",
        "  <div>{maps['Autumn']}</div>\n",
        "  <div>{maps['Winter']}</div>\n",
        "</div>\n",
        "\"\"\"\n",
        "\n",
        "# --- 9. Save Combined HTML File ---\n",
        "with open(\"temperature_maps_seasons_2019.html\", \"w\") as f:\n",
        "    f.write(html)\n",
        "\n",
        "# --- 10. Display in Notebook ---\n",
        "HTML(html)\n"
      ],
      "metadata": {
        "id": "aTF-rosUJ9Br"
      },
      "id": "aTF-rosUJ9Br",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(weather_2019.columns)\n"
      ],
      "metadata": {
        "id": "ajYGGrHaKFaL"
      },
      "id": "ajYGGrHaKFaL",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "xNDuE-JOslS-",
      "metadata": {
        "id": "xNDuE-JOslS-"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import folium\n",
        "import requests\n",
        "import us\n",
        "from IPython.display import HTML\n",
        "\n",
        "# --- 1. Define Seasons ---\n",
        "def get_season(month):\n",
        "    if month in [3, 4, 5]:\n",
        "        return \"Spring\"\n",
        "    elif month in [6, 7, 8]:\n",
        "        return \"Summer\"\n",
        "    elif month in [9, 10, 11]:\n",
        "        return \"Autumn\"\n",
        "    else:\n",
        "        return \"Winter\"\n",
        "\n",
        "# --- 2. Filter for Year 2019 ---\n",
        "weather_2020 = weather[weather[\"year\"] == 2020].copy()\n",
        "weather_2020[\"Season\"] = weather_2020[\"month\"].apply(get_season)\n",
        "\n",
        "# --- 3. Compute Average Temperature per State per Season ---\n",
        "seasonal_temps = (\n",
        "    weather_2020.groupby([\"state\", \"Season\"])[\"average_temp\"]\n",
        "    .mean()\n",
        "    .reset_index()\n",
        "    .rename(columns={\"state\": \"State\", \"average_temp\": \"Avg_Temperature\"})\n",
        ")\n",
        "\n",
        "# --- 4. Ensure State Abbreviations (for GeoJSON matching) ---\n",
        "if len(seasonal_temps[\"State\"].iloc[0]) > 2:\n",
        "    seasonal_temps[\"State\"] = seasonal_temps[\"State\"].map(\n",
        "        lambda x: us.states.lookup(x).abbr if us.states.lookup(x) else None\n",
        "    )\n",
        "\n",
        "# --- 5. Load US States GeoJSON ---\n",
        "url = \"https://raw.githubusercontent.com/python-visualization/folium/main/examples/data/us-states.json\"\n",
        "state_geo = requests.get(url).json()\n",
        "\n",
        "# --- 6. Helper Function to Create Seasonal Map ---\n",
        "def make_map(df, season):\n",
        "    temp_state = df[df[\"Season\"] == season]\n",
        "    m = folium.Map(location=[37.8, -96], zoom_start=4)\n",
        "    folium.Choropleth(\n",
        "        geo_data=state_geo,\n",
        "        data=temp_state,\n",
        "        columns=[\"State\", \"Avg_Temperature\"],\n",
        "        key_on=\"feature.id\",\n",
        "        fill_color=\"YlOrRd\",\n",
        "        fill_opacity=0.8,\n",
        "        line_opacity=0.3,\n",
        "        legend_name=f\"Average Temperature (°F) - {season} 2020\"\n",
        "    ).add_to(m)\n",
        "    return m._repr_html_()\n",
        "\n",
        "# --- 7. Create Maps for All Seasons ---\n",
        "maps = {}\n",
        "for season in [\"Spring\", \"Summer\", \"Autumn\", \"Winter\"]:\n",
        "    maps[season] = make_map(seasonal_temps, season)\n",
        "\n",
        "# --- 8. Combine into One HTML Dashboard ---\n",
        "html = f\"\"\"\n",
        "<h2 style=\"text-align:center;\">Average State Temperature (°F) by Season - 2020</h2>\n",
        "<div style=\"display:grid; grid-template-columns: 1fr 1fr; gap:10px;\">\n",
        "  <div>{maps['Spring']}</div>\n",
        "  <div>{maps['Summer']}</div>\n",
        "  <div>{maps['Autumn']}</div>\n",
        "  <div>{maps['Winter']}</div>\n",
        "</div>\n",
        "\"\"\"\n",
        "\n",
        "# --- 9. Save Combined HTML File ---\n",
        "with open(\"temperature_maps_seasons_2020.html\", \"w\") as f:\n",
        "    f.write(html)\n",
        "\n",
        "# --- 10. Display in Notebook ---\n",
        "HTML(html)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "C8ZHdh_XtdA-",
      "metadata": {
        "id": "C8ZHdh_XtdA-"
      },
      "outputs": [],
      "source": [
        "import us\n",
        "import requests\n",
        "import folium\n",
        "from IPython.display import HTML\n",
        "\n",
        "# --- 4. Ensure Full State Names (for GeoJSON matching) ---\n",
        "def to_full_state_name(x):\n",
        "    s = us.states.lookup(x)\n",
        "    return s.name if s else x  # Convert abbrev -> full name\n",
        "\n",
        "seasonal_temps[\"State\"] = seasonal_temps[\"State\"].apply(to_full_state_name)\n",
        "\n",
        "# --- 5. Load US States GeoJSON ---\n",
        "url = \"https://raw.githubusercontent.com/python-visualization/folium/main/examples/data/us-states.json\"\n",
        "state_geo = requests.get(url).json()\n",
        "\n",
        "# --- 6. Helper Function to Create Seasonal Map ---\n",
        "def make_map(df, season):\n",
        "    temp_state = df[df[\"Season\"] == season]\n",
        "    m = folium.Map(location=[37.8, -96], zoom_start=4)\n",
        "    folium.Choropleth(\n",
        "        geo_data=state_geo,\n",
        "        data=temp_state,\n",
        "        columns=[\"State\", \"Avg_Temperature\"],\n",
        "        key_on=\"feature.properties.name\",  # matches full state names\n",
        "        fill_color=\"YlOrRd\",\n",
        "        fill_opacity=0.8,\n",
        "        line_opacity=0.3,\n",
        "        nan_fill_color=\"white\",\n",
        "        legend_name=f\"Average Temperature (°F) - {season} 2021\"\n",
        "    ).add_to(m)\n",
        "    return m._repr_html_()\n",
        "\n",
        "# --- 7. Create Maps for All Seasons ---\n",
        "maps = {}\n",
        "for season in [\"Spring\", \"Summer\", \"Autumn\", \"Winter\"]:\n",
        "    maps[season] = make_map(seasonal_temps, season)\n",
        "\n",
        "# --- 8. Combine into One HTML Dashboard ---\n",
        "html = f\"\"\"\n",
        "<h2 style=\"text-align:center;\">Average State Temperature (°F) by Season - 2021</h2>\n",
        "<div style=\"display:grid; grid-template-columns: 1fr 1fr; gap:10px;\">\n",
        "  <div>{maps['Spring']}</div>\n",
        "  <div>{maps['Summer']}</div>\n",
        "  <div>{maps['Autumn']}</div>\n",
        "  <div>{maps['Winter']}</div>\n",
        "</div>\n",
        "\"\"\"\n",
        "\n",
        "# --- 9. Save Combined HTML File ---\n",
        "with open(\"temperature_maps_seasons_2021.html\", \"w\") as f:\n",
        "    f.write(html)\n",
        "\n",
        "# --- 10. Display in Notebook ---\n",
        "HTML(html)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2-555lQLwylp",
      "metadata": {
        "id": "2-555lQLwylp"
      },
      "source": [
        "####species counts and temps"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "IQhb2QH1y3od",
      "metadata": {
        "id": "IQhb2QH1y3od"
      },
      "outputs": [],
      "source": [
        "us_state_abbrev = {\n",
        "    \"AL\": \"Alabama\", \"AK\": \"Alaska\", \"AZ\": \"Arizona\", \"AR\": \"Arkansas\", \"CA\": \"California\",\n",
        "    \"CO\": \"Colorado\", \"CT\": \"Connecticut\", \"DE\": \"Delaware\", \"FL\": \"Florida\", \"GA\": \"Georgia\",\n",
        "    \"HI\": \"Hawaii\", \"ID\": \"Idaho\", \"IL\": \"Illinois\", \"IN\": \"Indiana\", \"IA\": \"Iowa\",\n",
        "    \"KS\": \"Kansas\", \"KY\": \"Kentucky\", \"LA\": \"Louisiana\", \"ME\": \"Maine\", \"MD\": \"Maryland\",\n",
        "    \"MA\": \"Massachusetts\", \"MI\": \"Michigan\", \"MN\": \"Minnesota\", \"MS\": \"Mississippi\", \"MO\": \"Missouri\",\n",
        "    \"MT\": \"Montana\", \"NE\": \"Nebraska\", \"NV\": \"Nevada\", \"NH\": \"New Hampshire\", \"NJ\": \"New Jersey\",\n",
        "    \"NM\": \"New Mexico\", \"NY\": \"New York\", \"NC\": \"North Carolina\", \"ND\": \"North Dakota\", \"OH\": \"Ohio\",\n",
        "    \"OK\": \"Oklahoma\", \"OR\": \"Oregon\", \"PA\": \"Pennsylvania\", \"RI\": \"Rhode Island\", \"SC\": \"South Carolina\",\n",
        "    \"SD\": \"South Dakota\", \"TN\": \"Tennessee\", \"TX\": \"Texas\", \"UT\": \"Utah\", \"VT\": \"Vermont\",\n",
        "    \"VA\": \"Virginia\", \"WA\": \"Washington\", \"WV\": \"West Virginia\", \"WI\": \"Wisconsin\", \"WY\": \"Wyoming\"\n",
        "}\n",
        "\n",
        "#count_te_species[\"State\"] = count_te_species[\"State\"].map(us_state_abbrev).fillna(count_te_species[\"State\"])\n",
        "\n",
        "# --- Biodiversity per state ---\n",
        "species_state = species.merge(parks[[\"Park Name\", \"State\"]], on=\"Park Name\", how=\"left\")\n",
        "biodiversity_state = (\n",
        "    species_state.groupby(\"State\")[\"Scientific Name\"]\n",
        "    .nunique()\n",
        "    .reset_index()\n",
        "    .rename(columns={\"Scientific Name\": \"Unique_Species\"})\n",
        ")\n",
        "\n",
        "# --- 2. Temperature per state (year 2021) ---\n",
        "weather_2020 = weather[weather[\"year\"] == 2020]\n",
        "temp_state = (\n",
        "    weather_2020.groupby(\"state\")[\"average_temp\"]\n",
        "    .mean()\n",
        "    .reset_index()\n",
        "    .rename(columns={\"state\": \"State\", \"average_temp\": \"Avg_Temperature\"})\n",
        ")\n",
        "\n",
        "# Convert full names → abbreviations if needed\n",
        "if len(temp_state[\"State\"].iloc[0]) > 2:\n",
        "    temp_state[\"State\"] = temp_state[\"State\"].map(\n",
        "        lambda x: us.states.lookup(x).abbr if us.states.lookup(x) else None\n",
        "    )\n",
        "\n",
        "# --- 3. Load GeoJSON ---\n",
        "url = \"https://raw.githubusercontent.com/python-visualization/folium/main/examples/data/us-states.json\"\n",
        "state_geo = requests.get(url).json()\n",
        "\n",
        "# --- 4. Create base map ---\n",
        "m = folium.Map(location=[40, -95], zoom_start=4, tiles=\"CartoDB positron\")\n",
        "\n",
        "# --- 5. Add biodiversity layer ---\n",
        "folium.Choropleth(\n",
        "    geo_data=state_geo,\n",
        "    name=\"Biodiversity (Unique Species)\",\n",
        "    data=biodiversity_state,\n",
        "    columns=[\"State\", \"Unique_Species\"],\n",
        "    key_on=\"feature.id\",\n",
        "    fill_color=\"YlGn\",\n",
        "    fill_opacity=0.7,\n",
        "    line_opacity=0.2,\n",
        "    legend_name=\"Unique Species per State\"\n",
        ").add_to(m)\n",
        "\n",
        "# --- 6. Add temperature layer ---\n",
        "folium.Choropleth(\n",
        "    geo_data=state_geo,\n",
        "    name=\"Average Temperature (°F, 2020)\",\n",
        "    data=temp_state,\n",
        "    columns=[\"State\", \"Avg_Temperature\"],\n",
        "    key_on=\"feature.id\",\n",
        "    fill_color=\"YlOrRd\",\n",
        "    fill_opacity=0.6,\n",
        "    line_opacity=0.3,\n",
        "    legend_name=\"Average Temperature (°F, 2020)\"\n",
        ").add_to(m)\n",
        "\n",
        "# --- 7. Add park markers ---\n",
        "for _, row in parks.iterrows():\n",
        "    folium.Marker(\n",
        "        location=[row[\"Latitude\"], row[\"Longitude\"]],\n",
        "        popup=f\"<b>{row['Park Name']}</b><br>State: {row['State']}<br>Acres: {row['Acres']:,}\",\n",
        "        icon=folium.Icon(color=\"green\", icon=\"tree\", prefix=\"fa\")\n",
        "    ).add_to(m)\n",
        "\n",
        "# --- 8. Add temperature markers (optional) ---\n",
        "for _, row in weather_2020.drop_duplicates(\"state\").iterrows():\n",
        "    folium.Marker(\n",
        "        location=[row[\"centroid_lat\"], row[\"centroid_lon\"]],\n",
        "        popup=f\"<b>{row['state']}</b><br>Avg Temp: {row['average_temp']:.1f}°F\",\n",
        "        icon=folium.Icon(color=\"red\", icon=\"thermometer-half\", prefix=\"fa\")\n",
        "    ).add_to(m)\n",
        "\n",
        "# --- 9. Layer control ---\n",
        "folium.LayerControl(collapsed=False).add_to(m)\n",
        "\n",
        "# --- 10. Save and show ---\n",
        "m.save(\"combined_biodiversity_temperature_map.html\")\n",
        "display(m)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "pJ2u66Ulw3tL",
      "metadata": {
        "id": "pJ2u66Ulw3tL"
      },
      "source": [
        "####threatened/endangered species count"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "wLxC7_r2elDk",
      "metadata": {
        "id": "wLxC7_r2elDk"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load both CSVs\n",
        "species = pd.read_csv(\"species.csv\", low_memory=False)\n",
        "parks = pd.read_csv(\"parks.csv\", low_memory=False)\n",
        "\n",
        "# --- 1. Merge to get states ---\n",
        "species_states = species.merge(\n",
        "    parks[[\"Park Name\", \"State\"]],\n",
        "    on=\"Park Name\",\n",
        "    how=\"left\"\n",
        ")\n",
        "\n",
        "# --- 2. Split multi-state entries like \"TN, NC\" into separate rows ---\n",
        "species_states[\"State\"] = species_states[\"State\"].str.split(\",\")\n",
        "species_states = species_states.explode(\"State\")\n",
        "species_states[\"State\"] = species_states[\"State\"].str.strip()\n",
        "\n",
        "# --- 3. Keep only State and Conservation Status ---\n",
        "species_states = species_states[[\"State\", \"Conservation Status\"]]\n",
        "\n",
        "# --- 4. Print unique state count and a sample ---\n",
        "unique_states = species_states[\"State\"].dropna().unique()\n",
        "print(f\"Number of unique states found: {len(unique_states)}\")\n",
        "print(\"States present:\", sorted(unique_states.tolist()))\n",
        "print(\"\\nSample of merged data:\")\n",
        "print(species_states.head(10))\n",
        "\n",
        "# --- 5. Create full list of 50 states for completeness ---\n",
        "us_states = [\n",
        "    'AL','AK','AZ','AR','CA','CO','CT','DE','FL','GA','HI','ID','IL','IN','IA','KS',\n",
        "    'KY','LA','ME','MD','MA','MI','MN','MS','MO','MT','NE','NV','NH','NJ','NM','NY',\n",
        "    'NC','ND','OH','OK','OR','PA','RI','SC','SD','TN','TX','UT','VT','VA','WA','WV','WI','WY'\n",
        "]\n",
        "\n",
        "# Make sure all states are represented — fill in missing ones with NaN\n",
        "missing = set(us_states) - set(species_states[\"State\"].dropna().unique())\n",
        "missing_df = pd.DataFrame({\"State\": list(missing), \"Conservation Status\": None})\n",
        "species_states_full = pd.concat([species_states, missing_df], ignore_index=True)\n",
        "\n",
        "print(f\"\\n✅ Final dataset includes all {species_states_full['State'].nunique()} states.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cy5K_skkhyAO",
      "metadata": {
        "id": "cy5K_skkhyAO"
      },
      "outputs": [],
      "source": [
        "# Define which statuses count as threatened/endangered\n",
        "te_statuses = [\"Threatened\", \"Proposed Endangered\", \"Proposed Threatened\", \"Endangered\"]\n",
        "\n",
        "# Filter only TE species\n",
        "te_species = species_states_full[species_states_full[\"Conservation Status\"].isin(te_statuses)]\n",
        "\n",
        "# Count unique occurrences per state\n",
        "te_count_species = (\n",
        "    te_species.groupby(\"State\")[\"Conservation Status\"]\n",
        "    .count()\n",
        "    .reset_index()\n",
        "    .rename(columns={\"Conservation Status\": \"count_te_species\"})\n",
        ")\n",
        "\n",
        "print(te_count_species.head())\n",
        "print(f\"\\nTotal states with at least one TE species: {len(te_count_species)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ZhXgHLcvWr1v",
      "metadata": {
        "id": "ZhXgHLcvWr1v"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import folium\n",
        "import requests\n",
        "from fuzzywuzzy import process\n",
        "\n",
        "# --- 1. Filter for Threatened/Endangered statuses ---\n",
        "te_statuses = [\"Threatened\", \"Proposed Endangered\", \"Proposed Threatened\", \"Endangered\"]\n",
        "species_filtered = species[species[\"Conservation Status\"].isin(te_statuses)].copy()\n",
        "\n",
        "# --- 2. Fuzzy match park names ---\n",
        "def match_park_name(park_name, park_list):\n",
        "    match, score = process.extractOne(park_name, park_list)\n",
        "    return match if score > 80 else None\n",
        "\n",
        "parks_list = parks[\"Park Name\"].unique()\n",
        "species_filtered[\"Matched Park Name\"] = species_filtered[\"Park Name\"].apply(lambda x: match_park_name(x, parks_list))\n",
        "\n",
        "# --- 3. Merge to get state info ---\n",
        "species_parks = pd.merge(\n",
        "    species_filtered,\n",
        "    parks[[\"Park Name\", \"State\"]],\n",
        "    left_on=\"Matched Park Name\",\n",
        "    right_on=\"Park Name\",\n",
        "    how=\"left\"\n",
        ")\n",
        "\n",
        "# --- 4. Split multi-state entries like \"TN, NC\" ---\n",
        "species_parks = species_parks.dropna(subset=[\"State\"])\n",
        "species_parks[\"State\"] = species_parks[\"State\"].str.split(\",\")\n",
        "species_parks = species_parks.explode(\"State\")\n",
        "species_parks[\"State\"] = species_parks[\"State\"].str.strip()\n",
        "\n",
        "# --- 5. Add mock Year if missing ---\n",
        "if \"Year\" not in species_parks.columns:\n",
        "    import numpy as np\n",
        "    species_parks[\"Year\"] = np.random.choice([2019, 2020, 2021], size=len(species_parks))\n",
        "\n",
        "# --- 6. State abbreviations ---\n",
        "us_state_abbrev = {\n",
        "    \"AL\": \"Alabama\", \"AK\": \"Alaska\", \"AZ\": \"Arizona\", \"AR\": \"Arkansas\", \"CA\": \"California\",\n",
        "    \"CO\": \"Colorado\", \"CT\": \"Connecticut\", \"DE\": \"Delaware\", \"FL\": \"Florida\", \"GA\": \"Georgia\",\n",
        "    \"HI\": \"Hawaii\", \"ID\": \"Idaho\", \"IL\": \"Illinois\", \"IN\": \"Indiana\", \"IA\": \"Iowa\",\n",
        "    \"KS\": \"Kansas\", \"KY\": \"Kentucky\", \"LA\": \"Louisiana\", \"ME\": \"Maine\", \"MD\": \"Maryland\",\n",
        "    \"MA\": \"Massachusetts\", \"MI\": \"Michigan\", \"MN\": \"Minnesota\", \"MS\": \"Mississippi\", \"MO\": \"Missouri\",\n",
        "    \"MT\": \"Montana\", \"NE\": \"Nebraska\", \"NV\": \"Nevada\", \"NH\": \"New Hampshire\", \"NJ\": \"New Jersey\",\n",
        "    \"NM\": \"New Mexico\", \"NY\": \"New York\", \"NC\": \"North Carolina\", \"ND\": \"North Dakota\", \"OH\": \"Ohio\",\n",
        "    \"OK\": \"Oklahoma\", \"OR\": \"Oregon\", \"PA\": \"Pennsylvania\", \"RI\": \"Rhode Island\", \"SC\": \"South Carolina\",\n",
        "    \"SD\": \"South Dakota\", \"TN\": \"Tennessee\", \"TX\": \"Texas\", \"UT\": \"Utah\", \"VT\": \"Vermont\",\n",
        "    \"VA\": \"Virginia\", \"WA\": \"Washington\", \"WV\": \"West Virginia\", \"WI\": \"Wisconsin\", \"WY\": \"Wyoming\"\n",
        "}\n",
        "\n",
        "species_parks[\"State\"] = species_parks[\"State\"].map(us_state_abbrev).fillna(species_parks[\"State\"])\n",
        "\n",
        "# --- 7. Load U.S. GeoJSON ---\n",
        "geo_url = \"https://raw.githubusercontent.com/python-visualization/folium/main/examples/data/us-states.json\"\n",
        "geo_data = requests.get(geo_url).json()\n",
        "\n",
        "# --- 8. Function to make a single map ---\n",
        "def create_te_map(year):\n",
        "    df_year = (\n",
        "        species_parks[species_parks[\"Year\"] == year]\n",
        "        .groupby(\"State\")[\"Species ID\"]\n",
        "        .nunique()\n",
        "        .reset_index()\n",
        "        .rename(columns={\"Species ID\": \"count_te_species\"})\n",
        "    )\n",
        "\n",
        "    all_states = pd.DataFrame(list(us_state_abbrev.values()), columns=[\"State\"])\n",
        "    df_year = pd.merge(all_states, df_year, on=\"State\", how=\"left\").fillna({\"count_te_species\": 0})\n",
        "\n",
        "    m = folium.Map(location=[37.8, -96], zoom_start=4, tiles=\"cartodb positron\")\n",
        "    bins = [0, 1, 5, 10, 20, 50, 100, 150]\n",
        "\n",
        "    choropleth = folium.Choropleth(\n",
        "        geo_data=geo_data,\n",
        "        data=df_year,\n",
        "        columns=[\"State\", \"count_te_species\"],\n",
        "        key_on=\"feature.properties.name\",\n",
        "        fill_color=\"YlOrRd\",\n",
        "        fill_opacity=0.85,\n",
        "        line_opacity=0.3,\n",
        "        nan_fill_color=\"#f0f0f0\",\n",
        "        legend_name=f\"Threatened/Endangered Species Count ({year})\",\n",
        "        bins=bins\n",
        "    ).add_to(m)\n",
        "\n",
        "    choropleth.geojson.add_child(\n",
        "        folium.features.GeoJsonTooltip(fields=[\"name\"], aliases=[\"State:\"], sticky=False)\n",
        "    )\n",
        "\n",
        "    return m\n",
        "\n",
        "# --- 9. Create and display each map separately ---\n",
        "m_2019 = create_te_map(2019)\n",
        "m_2020 = create_te_map(2020)\n",
        "m_2021 = create_te_map(2021)\n",
        "\n",
        "display(m_2019)\n",
        "display(m_2020)\n",
        "display(m_2021)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ibpwUegKtFoc",
      "metadata": {
        "id": "ibpwUegKtFoc"
      },
      "source": [
        "####heatmap of environmental variables and species counts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "GkMZ3UF8sfB4",
      "metadata": {
        "id": "GkMZ3UF8sfB4"
      },
      "outputs": [],
      "source": [
        "# Example species_summary dataframe\n",
        "species_summary = pd.DataFrame({\n",
        "    \"State_Name\": [\"Alaska\", \"Arizona\", \"Arkansas\", \"California\", \"Colorado\"],\n",
        "    \"species_richness\": [8864, 4687, 1155, 10083, 4506],\n",
        "    \"count_te_species\": [45, 23, 6, 100, 17],\n",
        "    \"State_Name_clean\": [\"alaska\", \"arizona\", \"arkansas\", \"california\", \"colorado\"],\n",
        "    # Example environmental variables (numeric)\n",
        "    \"Avg_Summer_Temp_2019_2021\": [50.0, 75.2, 70.1, 65.5, 60.0],\n",
        "    \"Avg_Winter_Temp_2019_2021\": [15.0, 40.2, 35.1, 50.5, 30.0],\n",
        "    \"log_acres\": [10.2, 8.5, 7.0, 12.1, 9.5],\n",
        "    \"log_deforestation\": [1.5, 2.1, 0.8, 3.0, 1.2]\n",
        "})\n",
        "\n",
        "# Step 1: Create species_count column\n",
        "species_summary['species_count'] = species_summary['species_richness']  # or count_te_species\n",
        "\n",
        "# Step 2: Select species_count + environmental variables\n",
        "env_vars = [\"Avg_Summer_Temp_2019_2021\", \"Avg_Winter_Temp_2019_2021\", \"log_acres\", \"log_deforestation\"]\n",
        "corr_data = species_summary[[\"species_count\"] + env_vars]\n",
        "\n",
        "# Step 3: Compute correlation matrix\n",
        "corr_matrix = corr_data.corr()\n",
        "\n",
        "# Step 4: Plot heatmap\n",
        "plt.figure(figsize=(8,6))\n",
        "sns.heatmap(corr_matrix, annot=True, cmap=\"coolwarm\", fmt=\".2f\")\n",
        "plt.title(\"Correlation Matrix: Environmental Variables vs. Species Count\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "51b9593c",
      "metadata": {
        "id": "51b9593c"
      },
      "source": [
        "# Preprocessing & Cleaning\n",
        "\n",
        "Data cleaning and preprocessing steps."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "lW-M8P9vMHvZ",
      "metadata": {
        "id": "lW-M8P9vMHvZ"
      },
      "source": [
        "###Checking for NaN values, removing if any, and checking dataframe shapes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "A9ZmAMzZ3-4G",
      "metadata": {
        "id": "A9ZmAMzZ3-4G"
      },
      "outputs": [],
      "source": [
        "weather[weather.isna().any(axis=1)]\n",
        "weather.dropna(axis=0)\n",
        "weather.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6b10037c",
      "metadata": {
        "id": "6b10037c"
      },
      "outputs": [],
      "source": [
        "deforestation[deforestation.isna().any(axis=1)]\n",
        "deforestation.dropna(axis=0)\n",
        "deforestation.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fc40380a",
      "metadata": {
        "id": "fc40380a"
      },
      "outputs": [],
      "source": [
        "parks[parks.isna().any(axis=1)]\n",
        "parks.dropna(axis=0)\n",
        "parks.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "afc14548",
      "metadata": {
        "id": "afc14548"
      },
      "outputs": [],
      "source": [
        "species.dropna(axis=0)\n",
        "species[species.isna().any(axis=1)]\n",
        "species.isna().sum()\n",
        "species.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "xoedTxg0ZDoQ",
      "metadata": {
        "id": "xoedTxg0ZDoQ"
      },
      "source": [
        "###Checking for duplicates, removing if any"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "MSRItmKp4IZ7",
      "metadata": {
        "id": "MSRItmKp4IZ7"
      },
      "outputs": [],
      "source": [
        "weather.duplicated().sum()\n",
        "weather.drop_duplicates(inplace=True)\n",
        "weather.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a1d104d6",
      "metadata": {
        "id": "a1d104d6"
      },
      "outputs": [],
      "source": [
        "parks.duplicated().sum()\n",
        "parks.drop_duplicates(inplace=True)\n",
        "parks.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8d8c0d6a",
      "metadata": {
        "id": "8d8c0d6a"
      },
      "outputs": [],
      "source": [
        "deforestation.duplicated().sum()\n",
        "deforestation.drop_duplicates(inplace=True)\n",
        "deforestation.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "83349eca",
      "metadata": {
        "id": "83349eca"
      },
      "outputs": [],
      "source": [
        "species.duplicated().sum()\n",
        "species.drop_duplicates(inplace=True)\n",
        "species.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "MYGpHZ36a6H1",
      "metadata": {
        "id": "MYGpHZ36a6H1"
      },
      "source": [
        "###Creating/editing new dataframes"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "UL-xRSUfdW-L",
      "metadata": {
        "id": "UL-xRSUfdW-L"
      },
      "source": [
        "####keeping columns we will need, removing others"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5n7OquLu4TMT",
      "metadata": {
        "id": "5n7OquLu4TMT"
      },
      "outputs": [],
      "source": [
        "weather.columns\n",
        "\n",
        "weather = weather[['year', 'month', 'state', 'average_temp', 'monthly_mean_from_1901_to_2000']]\n",
        "weather.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "GkLUPVAxa8Uf",
      "metadata": {
        "id": "GkLUPVAxa8Uf"
      },
      "outputs": [],
      "source": [
        "species.columns\n",
        "\n",
        "species = species[['Species ID', 'Nativeness', 'Conservation Status', 'Park Name', 'Common Names', 'Occurrence', 'Seasonality', 'Category', 'Record Status', 'Abundance']]\n",
        "species.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3fj-FMg2bCHA",
      "metadata": {
        "id": "3fj-FMg2bCHA"
      },
      "outputs": [],
      "source": [
        "parks.columns\n",
        "\n",
        "parks = parks[['Park Code', 'Park Name', 'State', 'Acres', 'Latitude', 'Longitude']]\n",
        "parks.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "DJ6TsYgXbLn3",
      "metadata": {
        "id": "DJ6TsYgXbLn3"
      },
      "outputs": [],
      "source": [
        "deforestation.columns\n",
        "\n",
        "deforestation = deforestation[['INVENTORY_YEAR', 'STATE_CODE', 'ESTIMATE', 'PLOT_COUNT']]\n",
        "deforestation.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "DsLQeLAUc-6X",
      "metadata": {
        "id": "DsLQeLAUc-6X"
      },
      "source": [
        "####Merge species/parks dataset so we can group by state & (state abbreviations key)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "rMOV9K3qdODD",
      "metadata": {
        "id": "rMOV9K3qdODD"
      },
      "outputs": [],
      "source": [
        "# merge species with parks using Park Name\n",
        "species_parks = pd.merge(species, parks[[\"Park Name\", \"State\"]],\n",
        "                         on=\"Park Name\", how=\"left\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "vkneUysPdOlg",
      "metadata": {
        "id": "vkneUysPdOlg"
      },
      "outputs": [],
      "source": [
        "#abbreviations state key\n",
        "state_lookup = {\n",
        "    \"AL\": \"Alabama\", \"AK\": \"Alaska\", \"AZ\": \"Arizona\", \"AR\": \"Arkansas\", \"CA\": \"California\",\n",
        "    \"CO\": \"Colorado\", \"CT\": \"Connecticut\", \"DE\": \"Delaware\", \"FL\": \"Florida\", \"GA\": \"Georgia\",\n",
        "    \"HI\": \"Hawaii\", \"ID\": \"Idaho\", \"IL\": \"Illinois\", \"IN\": \"Indiana\", \"IA\": \"Iowa\",\n",
        "    \"KS\": \"Kansas\", \"KY\": \"Kentucky\", \"LA\": \"Louisiana\", \"ME\": \"Maine\", \"MD\": \"Maryland\",\n",
        "    \"MA\": \"Massachusetts\", \"MI\": \"Michigan\", \"MN\": \"Minnesota\", \"MS\": \"Mississippi\",\n",
        "    \"MO\": \"Missouri\", \"MT\": \"Montana\", \"NE\": \"Nebraska\", \"NV\": \"Nevada\", \"NH\": \"New Hampshire\",\n",
        "    \"NJ\": \"New Jersey\", \"NM\": \"New Mexico\", \"NY\": \"New York\", \"NC\": \"North Carolina\",\n",
        "    \"ND\": \"North Dakota\", \"OH\": \"Ohio\", \"OK\": \"Oklahoma\", \"OR\": \"Oregon\", \"PA\": \"Pennsylvania\",\n",
        "    \"RI\": \"Rhode Island\", \"SC\": \"South Carolina\", \"SD\": \"South Dakota\", \"TN\": \"Tennessee\",\n",
        "    \"TX\": \"Texas\", \"UT\": \"Utah\", \"VT\": \"Vermont\", \"VA\": \"Virginia\", \"WA\": \"Washington\",\n",
        "    \"WV\": \"West Virginia\", \"WI\": \"Wisconsin\", \"WY\": \"Wyoming\", \"PR\": \"Puerto Rico\", \"GU\": \"Guam\"\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "vpz5jlYSdmTJ",
      "metadata": {
        "id": "vpz5jlYSdmTJ"
      },
      "source": [
        "####Create new columns: species_richness and te_count_species"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ecT5-ZhmdvC5",
      "metadata": {
        "id": "ecT5-ZhmdvC5"
      },
      "outputs": [],
      "source": [
        "#match abbrev to full name\n",
        "species_parks[\"State_Name\"] = species_parks[\"State\"].map(state_lookup)\n",
        "\n",
        "#native species\n",
        "native_species_parks = species_parks[species_parks['Nativeness'] == 'Native']\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "nr_K6iWAdw-m",
      "metadata": {
        "id": "nr_K6iWAdw-m"
      },
      "outputs": [],
      "source": [
        "#see what the new columns are\n",
        "print(species_parks.columns.tolist())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dRLuH3F5d2I9",
      "metadata": {
        "id": "dRLuH3F5d2I9"
      },
      "outputs": [],
      "source": [
        "# --- Count unique native species richness per state ---\n",
        "species_richness = (\n",
        "    native_species_parks.groupby(\"State_Name\")[\"Species ID\"].nunique().reset_index()\n",
        ")\n",
        "species_richness.rename(columns={\"Species ID\": \"species_richness\"}, inplace=True)\n",
        "print(\"\\033[1mCount unique species richness:\\033[0m\")\n",
        "print(species_richness.head())\n",
        "\n",
        "# --- Count threatened/endangered species per state ---\n",
        "te_statuses = [\"Threatened\", \"Proposed Endangered\", \"Proposed Threatened\", \"Endangered\"]\n",
        "te_species = species_parks[species_parks[\"Conservation Status\"].isin(te_statuses)]\n",
        "count_te_species = (\n",
        "    te_species.groupby(\"State_Name\")[\"Species ID\"].nunique().reset_index()\n",
        ")\n",
        "count_te_species.rename(columns={\"Species ID\": \"count_te_species\"}, inplace=True)\n",
        "\n",
        "# --- Combine into species_summary ---\n",
        "species_summary = pd.merge(\n",
        "    species_richness, count_te_species,\n",
        "    on=\"State_Name\", how=\"outer\"\n",
        ")\n",
        "\n",
        "# --- Clean up state names ---\n",
        "species_summary[\"State_Name_clean\"] = species_summary[\"State_Name\"].str.strip().str.lower()\n",
        "print(\"\\n✅ species_summary columns:\", species_summary.columns.tolist())\n",
        "print(species_summary.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Ra-t8PFzd2xo",
      "metadata": {
        "collapsed": true,
        "id": "Ra-t8PFzd2xo"
      },
      "outputs": [],
      "source": [
        "#print everything\n",
        "# Show all rows\n",
        "pd.set_option('display.max_rows', None)\n",
        "\n",
        "# Show all columns\n",
        "pd.set_option('display.max_columns', None)\n",
        "\n",
        "# Now print the entire dataframe\n",
        "print(species_summary)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "qIegvzC8l4or",
      "metadata": {
        "id": "qIegvzC8l4or"
      },
      "source": [
        "### Editing Deforestation so it uses the years 2019-2021"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "NkSF99wzl2af",
      "metadata": {
        "id": "NkSF99wzl2af"
      },
      "outputs": [],
      "source": [
        "# --- Ensure INVENTORY_YEAR is numeric ---\n",
        "deforestation[\"INVENTORY_YEAR\"] = pd.to_numeric(deforestation[\"INVENTORY_YEAR\"], errors=\"coerce\")\n",
        "\n",
        "# --- Filter deforestation data for 2019–2021 ---\n",
        "deforestation_filtered = deforestation[\n",
        "    (deforestation[\"INVENTORY_YEAR\"] >= 2019) & (deforestation[\"INVENTORY_YEAR\"] <= 2021)\n",
        "].copy()\n",
        "\n",
        "# --- Compute average ESTIMATE per state per year without dropping other columns ---\n",
        "deforestation_filtered[\"AVG_DEFORESTATION\"] = deforestation_filtered.groupby(\n",
        "    [\"INVENTORY_YEAR\", \"STATE_CODE\"]\n",
        ")[\"ESTIMATE\"].transform(\"mean\")\n",
        "\n",
        "# --- Optional: rename columns for clarity (if needed) ---\n",
        "deforestation_filtered.rename(columns={\"INVENTORY_YEAR\": \"YEAR\",\n",
        "                                       \"State_Name\": \"STATE\"}, inplace=True)\n",
        "\n",
        "# --- View results ---\n",
        "print(deforestation_filtered.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "tApUxQ3qtcvN",
      "metadata": {
        "id": "tApUxQ3qtcvN"
      },
      "outputs": [],
      "source": [
        "# --- 1. Prepare deforestation data ---\n",
        "# Convert year to numeric and filter for 2019–2021\n",
        "deforestation[\"INVENTORY_YEAR\"] = pd.to_numeric(deforestation[\"INVENTORY_YEAR\"], errors=\"coerce\")\n",
        "deforestation_filtered = deforestation[\n",
        "    (deforestation[\"INVENTORY_YEAR\"] >= 2019) & (deforestation[\"INVENTORY_YEAR\"] <= 2021)\n",
        "].copy()\n",
        "\n",
        "# Extract clean state names from STATE_CODE (handles \"1 Alabama\" → \"Alabama\")\n",
        "deforestation_filtered[\"State_Name_clean\"] = deforestation_filtered[\"STATE_CODE\"].apply(\n",
        "    lambda x: re.sub(r\"^\\d+\\s*\", \"\", str(x)).strip() if isinstance(x, str) else None\n",
        ")\n",
        "\n",
        "# Create lowercase version for merging\n",
        "deforestation_filtered[\"state_lower\"] = deforestation_filtered[\"State_Name_clean\"].str.lower()\n",
        "\n",
        "# Compute averages and totals per state-year\n",
        "deforestation_filtered[\"AVG_DEFORESTATION\"] = deforestation_filtered.groupby(\n",
        "    [\"INVENTORY_YEAR\", \"state_lower\"]\n",
        ")[\"ESTIMATE\"].transform(\"mean\")\n",
        "\n",
        "deforestation_filtered[\"TOTAL_PLOTS\"] = deforestation_filtered.groupby(\n",
        "    [\"INVENTORY_YEAR\", \"state_lower\"]\n",
        ")[\"PLOT_COUNT\"].transform(\"sum\")\n",
        "\n",
        "# --- 2. Prepare species summary data ---\n",
        "# Create lowercase state column for merge (if not already)\n",
        "species_summary[\"State_Name_clean\"] = species_summary[\"State_Name\"].str.strip().str.lower()\n",
        "\n",
        "# --- 3. Merge both datasets (adds ESTIMATE, AVG_DEFORESTATION, TOTAL_PLOTS, etc.) ---\n",
        "combined_df = pd.merge(\n",
        "    species_summary,\n",
        "    deforestation_filtered,\n",
        "    left_on=\"State_Name_clean\",\n",
        "    right_on=\"state_lower\",\n",
        "    how=\"left\"\n",
        ")\n",
        "\n",
        "# --- 4. Clean up and rename ---\n",
        "combined_df.drop(columns=[\"state_lower\"], inplace=True)\n",
        "combined_df.rename(columns={\"INVENTORY_YEAR\": \"YEAR\"}, inplace=True)\n",
        "\n",
        "# --- 5. Inspect results ---\n",
        "print(\"✅ Combined dataset preview:\")\n",
        "print(combined_df.head(10))\n",
        "print(\"\\nColumns in combined_df:\", combined_df.columns.tolist())\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Hs1-etNRjF8A",
      "metadata": {
        "id": "Hs1-etNRjF8A"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# --- Compute mean deforestation per state (2019–2021 average) ---\n",
        "avg_deforestation_by_state = (\n",
        "    combined_df.groupby(\"State_Name\", as_index=False)[\"AVG_DEFORESTATION\"]\n",
        "    .mean()\n",
        "    .sort_values(by=\"AVG_DEFORESTATION\", ascending=False)\n",
        ")\n",
        "\n",
        "# --- Plot ---\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.bar(\n",
        "    avg_deforestation_by_state[\"State_Name\"],\n",
        "    avg_deforestation_by_state[\"AVG_DEFORESTATION\"]\n",
        ")\n",
        "plt.xticks(rotation=90)\n",
        "plt.title(\"Average Deforestation per State (2019–2021)\")\n",
        "plt.xlabel(\"State\")\n",
        "plt.ylabel(\"Average Deforestation (ESTIMATE)\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3qNzUbMQmPGN",
      "metadata": {
        "id": "3qNzUbMQmPGN"
      },
      "source": [
        "### Editing weather so it uses the years 2019-2021"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Ua_wGCdUmb24",
      "metadata": {
        "id": "Ua_wGCdUmb24"
      },
      "outputs": [],
      "source": [
        "print(weather.columns.tolist())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "jGqNBwrvmMuy",
      "metadata": {
        "id": "jGqNBwrvmMuy"
      },
      "outputs": [],
      "source": [
        "# --- Make sure year is numeric ---\n",
        "weather[\"year\"] = pd.to_numeric(weather[\"year\"], errors=\"coerce\")\n",
        "\n",
        "# --- Filter weather data for 2019–2021 ---\n",
        "weather_filtered = weather[\n",
        "    (weather[\"year\"] >= 2019) & (weather[\"year\"] <= 2021)\n",
        "]\n",
        "\n",
        "# --- Compute average temperature per state per year ---\n",
        "avg_temp_state_yearly = (\n",
        "    weather_filtered.groupby([\"year\", \"state\"])[\"average_temp\"]\n",
        "    .mean()\n",
        "    .reset_index()\n",
        "    .rename(columns={\n",
        "        \"year\": \"Year\",\n",
        "        \"state\": \"State\",\n",
        "        \"average_temp\": \"Avg_Temperature\"\n",
        "    })\n",
        ")\n",
        "\n",
        "# --- View results ---\n",
        "print(avg_temp_state_yearly.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "HQ7ZsKezrFSJ",
      "metadata": {
        "id": "HQ7ZsKezrFSJ"
      },
      "outputs": [],
      "source": [
        "print(species.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bTzeVIl3nef0",
      "metadata": {
        "id": "bTzeVIl3nef0"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# --- Line plot of average temperature by state and year ---\n",
        "plt.figure(figsize=(12, 6))\n",
        "\n",
        "for state in avg_temp_state_yearly[\"State\"].unique():\n",
        "    state_data = avg_temp_state_yearly[avg_temp_state_yearly[\"State\"] == state]\n",
        "    plt.plot(state_data[\"Year\"], state_data[\"Avg_Temperature\"], marker=\"o\", label=state, alpha=0.6)\n",
        "\n",
        "plt.title(\"Average Seasonal Temperature by State (2019–2021)\")\n",
        "plt.xlabel(\"Year\")\n",
        "plt.ylabel(\"Average Temperature (°F)\")\n",
        "plt.grid(True, linestyle=\"--\", alpha=0.5)\n",
        "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', fontsize=\"small\", ncol=2)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "qE958t5lr6dg",
      "metadata": {
        "id": "qE958t5lr6dg"
      },
      "outputs": [],
      "source": [
        "deforestation_filtered = deforestation_filtered[['INVENTORY_YEAR', 'State_Name_clean', 'ESTIMATE', 'PLOT_COUNT', 'AVG_DEFORESTATION']]\n",
        "weather_filtered = weather_filtered[['year', 'month', 'state', 'average_temp', 'monthly_mean_from_1901_to_2000']]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9bd579a3",
      "metadata": {
        "id": "9bd579a3"
      },
      "source": [
        "# Exploratory Data Analysis (EDA)\n",
        "\n",
        "Visualizations and descriptive summaries."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "w_H_hp_eRRHf",
      "metadata": {
        "id": "w_H_hp_eRRHf"
      },
      "source": [
        "###Check for bias/unbalancing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fb7fYFt_xjO1",
      "metadata": {
        "id": "fb7fYFt_xjO1"
      },
      "outputs": [],
      "source": [
        "# Filter data for 2019–2021\n",
        "weather_filtered = weather[(weather[\"year\"] >= 2019) & (weather[\"year\"] <= 2021)]\n",
        "\n",
        "# Compute average temperature per state per year\n",
        "avg_temp_state_yearly = (\n",
        "    weather_filtered.groupby([\"year\", \"state\"])[\"average_temp\"]\n",
        "    .mean()\n",
        "    .reset_index()\n",
        "    .rename(columns={\"average_temp\": \"Avg_Temperature\"})\n",
        ")\n",
        "\n",
        "# Sort for neatness\n",
        "avg_temp_state_yearly = avg_temp_state_yearly.sort_values([\"year\", \"Avg_Temperature\"], ascending=[True, False])\n",
        "\n",
        "# Display first few rows\n",
        "avg_temp_state_yearly.head(10)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dBJdIQ2i0P0r",
      "metadata": {
        "id": "dBJdIQ2i0P0r"
      },
      "outputs": [],
      "source": [
        "# Filter data for 2019–2021\n",
        "weather_filtered = weather[(weather[\"year\"] >= 2019) & (weather[\"year\"] <= 2021)]\n",
        "\n",
        "# --- Add 'season' column ---\n",
        "def get_season(month):\n",
        "    if month in [12, 1, 2]:\n",
        "        return \"Winter\"\n",
        "    elif month in [3, 4, 5]:\n",
        "        return \"Spring\"\n",
        "    elif month in [6, 7, 8]:\n",
        "        return \"Summer\"\n",
        "    else:\n",
        "        return \"Fall\"\n",
        "\n",
        "weather_filtered[\"season\"] = weather_filtered[\"month\"].apply(get_season)\n",
        "\n",
        "# --- Compute average temperature per state per season ---\n",
        "avg_temp_state_season = (\n",
        "    weather_filtered.groupby([\"year\", \"season\", \"state\"])[\"average_temp\"]\n",
        "    .mean()\n",
        "    .reset_index()\n",
        "    .rename(columns={\"average_temp\": \"Avg_Temperature\"})\n",
        ")\n",
        "\n",
        "# --- Sort for neatness ---\n",
        "avg_temp_state_season = avg_temp_state_season.sort_values(\n",
        "    [\"year\", \"season\", \"Avg_Temperature\"], ascending=[True, True, False]\n",
        ")\n",
        "\n",
        "# --- Display ---\n",
        "avg_temp_state_season\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "t7bS0_lJ3CTY",
      "metadata": {
        "id": "t7bS0_lJ3CTY"
      },
      "outputs": [],
      "source": [
        "weather.nunique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "E1TmpKPX3FPv",
      "metadata": {
        "id": "E1TmpKPX3FPv"
      },
      "outputs": [],
      "source": [
        "weather[\"state\"].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "M2EKp0083LGN",
      "metadata": {
        "id": "M2EKp0083LGN"
      },
      "outputs": [],
      "source": [
        "weather[\"year\"].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "NMjepybAcUWm",
      "metadata": {
        "id": "NMjepybAcUWm"
      },
      "outputs": [],
      "source": [
        "deforestation['STATE_CODE'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d6534987",
      "metadata": {
        "id": "d6534987"
      },
      "outputs": [],
      "source": [
        "#deforestation\n",
        "print(deforestation['INVENTORY_YEAR'].value_counts().sort_index())\n",
        "print(deforestation['STATE_CODE'].value_counts())\n",
        "deforestation['PLOT_COUNT'].hist()\n",
        "\n",
        "#the counts per year are not balanced (theres a lot more in current years), we need to normalize by states per year\n",
        "# the rows with total need to be taken out of the mix\n",
        "# some states have a lot less (2 vs 11), we need to normalize by the acres, and exclude the territories (67, 70, 78)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "v08Y_3eHcPak",
      "metadata": {
        "id": "v08Y_3eHcPak"
      },
      "outputs": [],
      "source": [
        "species['Conservation Status'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0zWMcBJ9cL2X",
      "metadata": {
        "id": "0zWMcBJ9cL2X"
      },
      "outputs": [],
      "source": [
        "#biodiversity\n",
        "print(species['Category'].value_counts())\n",
        "print(species['Nativeness'].value_counts())\n",
        "print(species['Conservation Status'].value_counts())\n",
        "\n",
        "#notice category is heavily skewed towards plants and birds over otehr mammals\n",
        "#for nativeness we might want to make unknown its own group, there is a decent amount\n",
        "#for conservation it could be dominatated by safe species, we should seperate by concern, threatened, and endangered vs not at risk\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "XR9DdE3-Umsv",
      "metadata": {
        "id": "XR9DdE3-Umsv"
      },
      "source": [
        "#### models displaying unbalance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c56e5bdf",
      "metadata": {
        "id": "c56e5bdf"
      },
      "outputs": [],
      "source": [
        "category_counts = species['Category'].value_counts()\n",
        "\n",
        "# Plot\n",
        "plt.figure(figsize=(10,6))\n",
        "category_counts.plot(kind='bar', color='skyblue', edgecolor='black')\n",
        "plt.title(\"Species Distribution by Category\")\n",
        "plt.xlabel(\"Category\")\n",
        "plt.ylabel(\"Number of Species\")\n",
        "plt.xticks(rotation=45)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b217c3a3",
      "metadata": {
        "id": "b217c3a3"
      },
      "outputs": [],
      "source": [
        "fig, axes = plt.subplots(1, 2, figsize=(14,6))\n",
        "\n",
        "# Nativeness\n",
        "species['Nativeness'].value_counts().plot(kind='bar', ax=axes[0], color='lightblue')\n",
        "axes[0].set_title(\"Species by Nativeness\")\n",
        "axes[0].tick_params(axis='x', rotation=45)\n",
        "\n",
        "# Conservation Status (top 6 to avoid overcrowding)\n",
        "species['Conservation Status'].value_counts().nlargest(6).plot(kind='bar', ax=axes[1], color='salmon')\n",
        "axes[1].set_title(\"Top Conservation Status Categories\")\n",
        "axes[1].tick_params(axis='x', rotation=45)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c193cf44",
      "metadata": {
        "id": "c193cf44"
      },
      "outputs": [],
      "source": [
        "deforestation['INVENTORY_YEAR'].value_counts().sort_index().plot(\n",
        "    kind='bar',\n",
        "    color='skyblue',\n",
        "    edgecolor='black',\n",
        "    figsize=(12,6)\n",
        ")\n",
        "\n",
        "plt.title(\"Distribution of Records Over Time\")\n",
        "plt.xlabel(\"Year\")\n",
        "plt.ylabel(\"Count\")\n",
        "plt.xticks(rotation=45)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5c218fa4",
      "metadata": {
        "id": "5c218fa4"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(12,6))\n",
        "sns.countplot(data=species, x=\"Nativeness\", hue=\"Conservation Status\")\n",
        "plt.title(\"Conservation Status by Nativeness\")\n",
        "plt.xticks(rotation=45)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2559664e",
      "metadata": {
        "id": "2559664e"
      },
      "outputs": [],
      "source": [
        "sns.boxplot(data=species, x=\"Category\", y=\"Abundance\")\n",
        "plt.xticks(rotation=90)\n",
        "plt.title(\"Distribution of Abundance Across Categories\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "MtrcyCVabx56",
      "metadata": {
        "id": "MtrcyCVabx56"
      },
      "source": [
        "###Summary Statistics of each column of each dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4-rsbjr3b2RC",
      "metadata": {
        "id": "4-rsbjr3b2RC"
      },
      "outputs": [],
      "source": [
        "print(parks.describe())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0m9EbaRDb36m",
      "metadata": {
        "id": "0m9EbaRDb36m"
      },
      "outputs": [],
      "source": [
        "print(species.describe())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "VNpfJDdTb7nj",
      "metadata": {
        "id": "VNpfJDdTb7nj"
      },
      "outputs": [],
      "source": [
        "print(deforestation.describe())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "v9AFxXLeefbM",
      "metadata": {
        "id": "v9AFxXLeefbM"
      },
      "source": [
        "###Descriptive Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "tsGEoIbtf7Jt",
      "metadata": {
        "id": "tsGEoIbtf7Jt"
      },
      "source": [
        "####Basic counts"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "LjHcQP7nfuD9",
      "metadata": {
        "id": "LjHcQP7nfuD9"
      },
      "source": [
        "#####count of different categories of species"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "nuBLYQ7ufwmc",
      "metadata": {
        "id": "nuBLYQ7ufwmc"
      },
      "outputs": [],
      "source": [
        "species.groupby('Category')['Species ID'].count()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3VOFBu7Jf06k",
      "metadata": {
        "id": "3VOFBu7Jf06k"
      },
      "source": [
        "#####count of different species in each park"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "-UCkT92Nf58W",
      "metadata": {
        "id": "-UCkT92Nf58W"
      },
      "outputs": [],
      "source": [
        "species.groupby(['Park Name', 'Category'])['Species ID'].count()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0hpi6G3mgEMo",
      "metadata": {
        "id": "0hpi6G3mgEMo"
      },
      "source": [
        "#####average estimate and plot count per state"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "UPk0uRG2gN1h",
      "metadata": {
        "id": "UPk0uRG2gN1h"
      },
      "outputs": [],
      "source": [
        "deforestation.groupby('STATE_CODE')[['ESTIMATE', 'PLOT_COUNT']].mean()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "jTaCRjIxgzfs",
      "metadata": {
        "id": "jTaCRjIxgzfs"
      },
      "source": [
        "#####counts of native vs nonnative species per category"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "u1sKFZTjg_HK",
      "metadata": {
        "id": "u1sKFZTjg_HK"
      },
      "outputs": [],
      "source": [
        "pd.crosstab(index=species_parks[\"Category\"],\n",
        "            columns=species_parks[\"Nativeness\"],\n",
        "            margins=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ctDQUzLqekB-",
      "metadata": {
        "id": "ctDQUzLqekB-"
      },
      "source": [
        "####Acres of parks in each state (mean, median, max - largest park in state, min - smallest, and count - number of parks per state)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "i8EIjXseBSLo",
      "metadata": {
        "id": "i8EIjXseBSLo"
      },
      "outputs": [],
      "source": [
        "parks['Acres'].mean()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "YCK-ftNVehiT",
      "metadata": {
        "id": "YCK-ftNVehiT"
      },
      "outputs": [],
      "source": [
        "parks.groupby('State')['Acres'].agg(['mean', 'median', 'max', 'min', 'count']).head"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3Tzcjqfie4sm",
      "metadata": {
        "id": "3Tzcjqfie4sm"
      },
      "outputs": [],
      "source": [
        "#total number of parks and acreage area per state\n",
        "parks.groupby('State')['Acres'].agg(['count', 'sum'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "hWeFxLAjfGzw",
      "metadata": {
        "id": "hWeFxLAjfGzw"
      },
      "outputs": [],
      "source": [
        "#largest park in each state\n",
        "parks.loc[parks.groupby('State')['Acres'].idxmax(), ['State', 'Park Name', 'Acres']]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "hjdz1qoNgmRo",
      "metadata": {
        "id": "hjdz1qoNgmRo"
      },
      "source": [
        "####Track deforestation over time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "zZu4hnl-go9w",
      "metadata": {
        "id": "zZu4hnl-go9w"
      },
      "outputs": [],
      "source": [
        "deforestation.groupby('INVENTORY_YEAR')['ESTIMATE'].agg(['mean', 'sum', 'max'])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "684ce766",
      "metadata": {
        "id": "684ce766"
      },
      "source": [
        "# Statistical Analysis\n",
        "\n",
        "Statistical tests, correlations, regression analysis, and hypothesis testing."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "rHAU5VZcWrco",
      "metadata": {
        "id": "rHAU5VZcWrco"
      },
      "source": [
        "###Chi-2 Contingency tests"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "g_qjMN77U-pV",
      "metadata": {
        "id": "g_qjMN77U-pV"
      },
      "source": [
        "####Tests whether deforestation estimate levels differ significantly across states"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8f7206de",
      "metadata": {
        "id": "8f7206de"
      },
      "outputs": [],
      "source": [
        "# Bin ESTIMATE into categories (Low, Medium, High)\n",
        "deforestation[\"EstimateClass\"] = pd.qcut(deforestation[\"ESTIMATE\"], q=3, labels=[\"Low\", \"Medium\", \"High\"])\n",
        "\n",
        "# Crosstab: State × EstimateClass\n",
        "obs_defor = pd.crosstab(deforestation[\"STATE_CODE\"], deforestation[\"EstimateClass\"])\n",
        "\n",
        "chi2, p, dof, ex = chi2_contingency(obs_defor)\n",
        "print(\"\\nDeforestation dataset:\")\n",
        "print(f\"Chi2 = {chi2:.3f}, p = {p:.5f}, dof = {dof}\")\n",
        "print(pd.DataFrame(ex, index=obs_defor.index, columns=obs_defor.columns))\n",
        "\n",
        "\n",
        "# Sort by total for readability (optional)\n",
        "obs_defor_sorted = obs_defor.sort_values(by=[\"High\", \"Medium\", \"Low\"], ascending=False)\n",
        "\n",
        "# Plot stacked bars\n",
        "obs_defor_sorted.plot(kind=\"bar\", stacked=True, figsize=(14,7),\n",
        "                      color=[\"#b3e2cd\", \"#fdcdac\", \"#f4a582\"], edgecolor=\"black\")\n",
        "\n",
        "plt.title(\"Deforestation Estimate Categories by State\", fontsize=16)\n",
        "plt.xlabel(\"State Code\")\n",
        "plt.ylabel(\"Number of Observations\")\n",
        "plt.legend(title=\"Estimate Class\", loc=\"upper right\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3C0YGV1MVWEu",
      "metadata": {
        "id": "3C0YGV1MVWEu"
      },
      "source": [
        "####Tests whether park size category is associated with state"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c78465fd",
      "metadata": {
        "id": "c78465fd"
      },
      "outputs": [],
      "source": [
        "# Create size class (e.g., large vs small parks based on median)\n",
        "parks[\"SizeClass\"] = np.where(parks[\"Acres\"] > parks[\"Acres\"].median(), \"Large\", \"Small\")\n",
        "\n",
        "# Crosstab: State × SizeClass\n",
        "obs_parks = pd.crosstab(parks[\"State\"], parks[\"SizeClass\"])\n",
        "\n",
        "# Chi-square test\n",
        "chi2, p, dof, ex = chi2_contingency(obs_parks)\n",
        "print(\"Parks dataset:\")\n",
        "print(f\"Chi2 = {chi2:.3f}, p = {p:.5f}, dof = {dof}\")\n",
        "print(pd.DataFrame(ex, index=obs_parks.index, columns=obs_parks.columns))\n",
        "\n",
        "'''\n",
        "Interpretation:\n",
        "The Chi-square test examines whether park size classification (Large vs Small)\n",
        "is associated with the state. The p-value (p = 0.39153) is greater than 0.05,\n",
        "indicating there is no statistically significant relationship between park size\n",
        "and state — in other words, large and small parks are fairly evenly distributed\n",
        "across states. The expected frequencies shown below represent the counts we would\n",
        "expect if size and state were independent, so this makes sense logically.\n",
        "'''\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "n7WniCQcVuX9",
      "metadata": {
        "id": "n7WniCQcVuX9"
      },
      "source": [
        "####Checks if species nativeness is related to category"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "640f8c34",
      "metadata": {
        "id": "640f8c34"
      },
      "outputs": [],
      "source": [
        "# Crosstab: Nativeness × Category\n",
        "obs_species = pd.crosstab(species[\"Nativeness\"], species[\"Category\"])\n",
        "\n",
        "chi2, p, dof, ex = chi2_contingency(obs_species)\n",
        "print(\"\\nSpecies dataset:\")\n",
        "print(f\"Chi2 = {chi2:.3f}, p = {p:.5f}, dof = {dof}\")\n",
        "print(pd.DataFrame(ex, index=obs_species.index, columns=obs_species.columns))\n",
        "\n",
        "'''\n",
        "Interpretation:\n",
        "The Chi-square test checks whether a species’ nativeness status (e.g., Native, Not Native)\n",
        "is related to its biological category (e.g., Bird, Fish, Plant, etc.).\n",
        "The Chi-square statistic is extremely large (Chi2 = 30718.978) and the p-value is effectively 0 (p < 0.001),\n",
        "indicating a highly significant association between nativeness and category.\n",
        "This means that the distribution of species’ nativeness varies substantially by category —\n",
        "for example, some categories may contain proportionally more native species, while others\n",
        "include more non-native or unknown species. The expected frequencies shown below represent\n",
        "the counts we would expect if nativeness and category were independent.\n",
        "'''"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "tSAsbpciXSXt",
      "metadata": {
        "id": "tSAsbpciXSXt"
      },
      "source": [
        "##### Interpretations of Chi-2 Test"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3jG1eMpHYP_r",
      "metadata": {
        "id": "3jG1eMpHYP_r"
      },
      "source": [
        "Chi-Square Tests  \n",
        "**a.** Deforestation Estimates by State: The Chi-Square test showed no significant relationship (p > 0.05) between deforestation estimate categories (Low, Medium, High) and individual states. Interpretation: This means that deforestation levels do not differ drastically between states in a statistically meaningful way. Forest loss is a widespread issue rather than being concentrated in specific regions.\n",
        "\n",
        "**b.** Park Size vs. State: The Chi-Square test for park size (classified as 'Large' or 'Small') across states found no significant relationship (p = 0.3915). Interpretation: Large and small parks are evenly distributed nationwide, suggesting that park size depends on geography rather than policy.\n",
        "\n",
        "**c.** Species Nativeness vs. Category: This test showed a highly significant relationship between species nativeness and category (χ² = 30,718.978, p < 0.001). Interpretation: There is a clear association between a species’ category (e.g., Bird, Plant, Mammal) and whether it is native or not. Some groups, like plants and birds, contain proportionally more native species."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Ah7OZ_eDNjlB",
      "metadata": {
        "id": "Ah7OZ_eDNjlB"
      },
      "source": [
        "###Mann-Whitney U testing"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "EnFX_6E0OTqt",
      "metadata": {
        "id": "EnFX_6E0OTqt"
      },
      "source": [
        "####estimates for earlier vs later years"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0ceda252",
      "metadata": {
        "id": "0ceda252"
      },
      "outputs": [],
      "source": [
        "# Convert INVENTORY_YEAR to numeric\n",
        "deforestation[\"INVENTORY_YEAR\"] = pd.to_numeric(deforestation[\"INVENTORY_YEAR\"], errors=\"coerce\")\n",
        "\n",
        "# Drop rows where conversion failed (if any)\n",
        "deforestation = deforestation.dropna(subset=[\"INVENTORY_YEAR\"])\n",
        "\n",
        "# Now split into early vs late\n",
        "early_estimate = deforestation[deforestation[\"INVENTORY_YEAR\"] <= 2020][\"ESTIMATE\"]\n",
        "late_estimate = deforestation[deforestation[\"INVENTORY_YEAR\"] > 2020][\"ESTIMATE\"]\n",
        "\n",
        "\n",
        "stat, p = mannwhitneyu(early_estimate, late_estimate)\n",
        "print(f\"Mann-Whitney U stat = {stat}, p = {p:.5f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1Mce-H8vORsx",
      "metadata": {
        "id": "1Mce-H8vORsx"
      },
      "source": [
        "####test for species richness compared to estimate in merged dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "NAa-vs1JmYUx",
      "metadata": {
        "id": "NAa-vs1JmYUx"
      },
      "outputs": [],
      "source": [
        "deforestation.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5iVTTeaPoEm0",
      "metadata": {
        "id": "5iVTTeaPoEm0"
      },
      "outputs": [],
      "source": [
        "species_summary.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "-p_98sUO-ol5",
      "metadata": {
        "id": "-p_98sUO-ol5"
      },
      "outputs": [],
      "source": [
        "# --- Extract state names from STATE_CODE (remove numeric prefix) ---\n",
        "deforestation[\"State_Name\"] = deforestation[\"STATE_CODE\"].apply(lambda x: re.sub(r'^\\d+\\s+', '', x))\n",
        "\n",
        "# --- Create lowercase clean state name ---\n",
        "deforestation[\"State_Name_clean\"] = deforestation[\"State_Name\"].str.strip().str.lower()\n",
        "\n",
        "# --- Keep only states that appear in both ---\n",
        "valid_states = species_summary[\"State_Name_clean\"].unique()\n",
        "deforestation_filtered = deforestation[deforestation[\"State_Name_clean\"].isin(valid_states)]\n",
        "\n",
        "# --- Merge biodiversity and deforestation ---\n",
        "merged_final = pd.merge(\n",
        "    deforestation_filtered,\n",
        "    species_summary,\n",
        "    on=\"State_Name_clean\",\n",
        "    how=\"left\"\n",
        ")\n",
        "\n",
        "print(\"\\n✅ final merged dataset columns:\", merged_final.columns.tolist())\n",
        "print(merged_final.head())\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "mHnCSekQhOmF",
      "metadata": {
        "id": "mHnCSekQhOmF"
      },
      "source": [
        "####Checks significance between large and small parks (based on acreage)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "VhuE9zcHhZGM",
      "metadata": {
        "id": "VhuE9zcHhZGM"
      },
      "outputs": [],
      "source": [
        "# Large vs Small parks\n",
        "parks[\"SizeClass\"] = np.where(parks[\"Acres\"] > parks[\"Acres\"].median(), \"Large\", \"Small\")\n",
        "\n",
        "large_acres = parks[parks[\"SizeClass\"] == \"Large\"][\"Acres\"]\n",
        "small_acres = parks[parks[\"SizeClass\"] == \"Small\"][\"Acres\"]\n",
        "\n",
        "stat, p = mannwhitneyu(large_acres, small_acres)\n",
        "print(f\"Mann-Whitney U stat = {stat}, p = {p:.11f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "hMzgExtMObHD",
      "metadata": {
        "id": "hMzgExtMObHD"
      },
      "source": [
        "####“Do states with higher deforestation have significantly different numbers of threatened species than states with lower deforestation?”"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fff9795e",
      "metadata": {
        "id": "fff9795e"
      },
      "outputs": [],
      "source": [
        "# Drop rows with missing values\n",
        "data = merged_final.dropna(subset=['ESTIMATE', 'count_te_species'])\n",
        "\n",
        "# Create binary group: High vs. Low deforestation based on median\n",
        "median_estimate = data['ESTIMATE'].median()\n",
        "data['Deforestation_Group'] = np.where(data['ESTIMATE'] > median_estimate, 'High', 'Low')\n",
        "\n",
        "# Split threatened species counts into two groups\n",
        "high_def = data[data['Deforestation_Group'] == 'High']['count_te_species']\n",
        "low_def = data[data['Deforestation_Group'] == 'Low']['count_te_species']\n",
        "\n",
        "# Mann–Whitney U test\n",
        "stat, p = mannwhitneyu(high_def, low_def, alternative='two-sided')\n",
        "\n",
        "print(f\"Mann–Whitney U statistic: {stat:.2f}\")\n",
        "print(f\"P-value: {p:.4f}\")\n",
        "\n",
        "if p < 0.05:\n",
        "    print(\"✅ Significant difference between High and Low deforestation states.\")\n",
        "else:\n",
        "    print(\"❌ No significant difference between High and Low deforestation states.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "vZa3ishbQyR0",
      "metadata": {
        "id": "vZa3ishbQyR0"
      },
      "outputs": [],
      "source": [
        "print(\"Median threatened species in High deforestation states:\", high_def.median())\n",
        "print(\"Median threatened species in Low deforestation states:\", low_def.median())\n",
        "\n",
        "#output states with lower deforestation have higher numbers of threatened species than those with higher deforestation."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "g_a0LDaOOkAU",
      "metadata": {
        "id": "g_a0LDaOOkAU"
      },
      "source": [
        "####“Do species counts (or threatened species counts) differ significantly between Western and Eastern states based on their deforestation estimates?”"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "06a15982",
      "metadata": {
        "id": "06a15982"
      },
      "outputs": [],
      "source": [
        "#categorize states\n",
        "west_states = [\n",
        "    'ak', 'az', 'ca', 'co', 'hi', 'id', 'mt', 'nv', 'nm', 'or', 'ut', 'wa', 'wy'\n",
        "]\n",
        "east_states = [\n",
        "    'al', 'ar', 'ct', 'de', 'fl', 'ga', 'il', 'in', 'ia', 'ks', 'ky', 'la', 'me', 'md',\n",
        "    'ma', 'mi', 'mn', 'ms', 'mo', 'ne', 'nh', 'nj', 'ny', 'nc', 'nd', 'oh', 'ok', 'pa',\n",
        "    'ri', 'sc', 'sd', 'tn', 'tx', 'vt', 'va', 'wv', 'wi'\n",
        "]\n",
        "\n",
        "# Drop rows with missing values\n",
        "data = merged_final.dropna(subset=['ESTIMATE', 'species_richness'])\n",
        "\n",
        "# Create Region column based on State_Name_clean\n",
        "data['Region'] = np.where(\n",
        "    data['State_Name_clean'].isin(west_states), 'West',\n",
        "    np.where(data['State_Name_clean'].isin(east_states), 'East', 'Other')\n",
        ")\n",
        "\n",
        "# Filter to East and West only\n",
        "data = data[data['Region'].isin(['East', 'West'])]\n",
        "\n",
        "# Split species richness by region\n",
        "west_species = data[data['Region'] == 'West']['species_richness']\n",
        "east_species = data[data['Region'] == 'East']['species_richness']\n",
        "\n",
        "# Mann–Whitney U test\n",
        "stat, p = mannwhitneyu(west_species, east_species, alternative='two-sided')\n",
        "\n",
        "print(f\"Mann–Whitney U statistic: {stat:.2f}\")\n",
        "print(f\"P-value: {p:.4f}\")\n",
        "\n",
        "if p < 0.05:\n",
        "    print(\"✅ Significant difference in species richness between East and West regions.\")\n",
        "else:\n",
        "    print(\"❌ No significant difference in species richness between East and West regions.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "EGfonyOOW7xX",
      "metadata": {
        "id": "EGfonyOOW7xX"
      },
      "source": [
        "####Tests if species rishness differes between high and low deforestation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0ce386a0",
      "metadata": {
        "id": "0ce386a0"
      },
      "outputs": [],
      "source": [
        "# Define a threshold (median deforestation value)\n",
        "threshold = data['ESTIMATE'].median()\n",
        "\n",
        "# Split into two groups\n",
        "low_deforestation = data[data['ESTIMATE'] <= threshold]['species_richness']\n",
        "high_deforestation = data[data['ESTIMATE'] > threshold]['species_richness']\n",
        "\n",
        "# Perform Mann-Whitney U Test\n",
        "stat, p = mannwhitneyu(low_deforestation, high_deforestation, alternative='two-sided')\n",
        "\n",
        "print(f\"Mann-Whitney U statistic: {stat:.4f}\")\n",
        "print(f\"P-value: {p:.4f}\")\n",
        "\n",
        "# Interpret\n",
        "if p < 0.05:\n",
        "    print(\"✅ Significant difference: species richness differs between high and low deforestation areas.\")\n",
        "else:\n",
        "    print(\"❌ No significant difference: deforestation does not appear to impact species richness significantly.\")\n",
        "\n",
        "'''\n",
        "Interpretation:\n",
        "The Mann-Whitney U test compares species richness between areas with low and high deforestation.\n",
        "The U statistic (3821.5) and p-value (p = 0.0698) indicate that the difference in species richness\n",
        "between the two groups is not statistically significant at the 0.05 level.\n",
        "This suggests that, based on the current data, there is no strong evidence that deforestation level\n",
        "significantly affects species richness — though the p-value is close to 0.05, implying a potential trend\n",
        "that might become significant with more data or refined measurements.\n",
        "'''"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "YhGHZwwVY4XO",
      "metadata": {
        "id": "YhGHZwwVY4XO"
      },
      "source": [
        "##### Interpretations of Mann-Whitney U test"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bLZPR02tY53L",
      "metadata": {
        "id": "bLZPR02tY53L"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "7SWY-sAMXFCn",
      "metadata": {
        "id": "7SWY-sAMXFCn"
      },
      "source": [
        "###T-test tests"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "nJdfhX8SXR0V",
      "metadata": {
        "id": "nJdfhX8SXR0V"
      },
      "source": [
        "####parks dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "819825b0",
      "metadata": {
        "id": "819825b0"
      },
      "outputs": [],
      "source": [
        "stat, p = ttest_ind(large_acres, small_acres, equal_var=False)  # Welch's t-test\n",
        "print(f\"Parks dataset: t-stat = {stat:.3f}, p-value = {p:.5f}\")\n",
        "\n",
        "if p < 0.05:\n",
        "    print(\"✅ Significant difference: Large parks have significantly different average acreage than small parks.\")\n",
        "else:\n",
        "    print(\"❌ No significant difference: There is no evidence of a difference in average acreage between large and small parks.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3nQ5j2vpXUpD",
      "metadata": {
        "id": "3nQ5j2vpXUpD"
      },
      "source": [
        "####deforestation dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a7b42d2b",
      "metadata": {
        "id": "a7b42d2b"
      },
      "outputs": [],
      "source": [
        "stat, p = ttest_ind(early_estimate, late_estimate, equal_var=False)\n",
        "print(f\"Deforestation dataset: t-stat = {stat:.3f}, p-value = {p:.5f}\")\n",
        "\n",
        "if np.isnan(stat) or np.isnan(p):\n",
        "    print(\"⚠️ Test could not be performed: one or both samples are too small or contain only missing values.\")\n",
        "else:\n",
        "    if p < 0.05:\n",
        "        print(\"✅ Significant difference: Average deforestation estimates differ significantly between early and late years.\")\n",
        "    else:\n",
        "        print(\"❌ No significant difference: Average deforestation estimates are statistically similar between early and late years.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "YwYfDfTcZH23",
      "metadata": {
        "id": "YwYfDfTcZH23"
      },
      "source": [
        "##### Interpretation of T-test"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cC82k4U7ZU4V",
      "metadata": {
        "id": "cC82k4U7ZU4V"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "ATr8xgNlOGwB",
      "metadata": {
        "id": "ATr8xgNlOGwB"
      },
      "source": [
        "#Models"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "OTzCAYCqOI2I",
      "metadata": {
        "id": "OTzCAYCqOI2I"
      },
      "source": [
        "##Prototypes 1 & 2: (species_richness, count_te_species)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "JzA5jSMgQXKD",
      "metadata": {
        "id": "JzA5jSMgQXKD"
      },
      "outputs": [],
      "source": [
        "#standardize to all lower and no spaces\n",
        "merged_final.columns = merged_final.columns.str.lower().str.strip()\n",
        "print(merged_final.columns.tolist())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "WWAqUXQ0Qet4",
      "metadata": {
        "id": "WWAqUXQ0Qet4"
      },
      "outputs": [],
      "source": [
        "numeric_cols = ['estimate', 'plot_count', 'species_richness', 'count_te_species']\n",
        "print(merged_final[numeric_cols].dtypes)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "FFHpjxd3XhUj",
      "metadata": {
        "id": "FFHpjxd3XhUj"
      },
      "outputs": [],
      "source": [
        "import statsmodels.api as sm\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# --- Clean and prepare dataset ---\n",
        "df = merged_final.copy()\n",
        "\n",
        "# Ensure numeric and drop missing values\n",
        "df[\"inventory_year\"] = pd.to_numeric(df[\"inventory_year\"], errors=\"coerce\")\n",
        "df = df.dropna(subset=[\"estimate\", \"plot_count\", \"species_richness\", \"count_te_species\", \"inventory_year\"])\n",
        "\n",
        "# --- Function to fit and summarize a model ---\n",
        "def fit_model(y_col, X_cols, df):\n",
        "    X = df[X_cols].copy()\n",
        "    X = sm.add_constant(X)\n",
        "    y = df[y_col]\n",
        "    model = sm.OLS(y, X).fit()\n",
        "    return model\n",
        "\n",
        "# --- Function to interpret model results ---\n",
        "def interpret_model(model, y_label):\n",
        "    coef = model.params\n",
        "    pvals = model.pvalues\n",
        "    print(f\"\\n📊 INTERPRETATION FOR: {y_label.upper()}\")\n",
        "    print(f\"- Intercept: {coef['const']:.2f}\")\n",
        "    for var in coef.index[1:]:\n",
        "        print(f\"- {var}: {coef[var]:.4f} (p = {pvals[var]:.4f})\")\n",
        "        if pvals[var] < 0.05:\n",
        "            direction = \"increase\" if coef[var] > 0 else \"decrease\"\n",
        "            print(f\"→ Statistically significant: As {var} increases, {y_label.lower()} tends to {direction}.\")\n",
        "        else:\n",
        "            print(f\"→ Not statistically significant (p ≥ 0.05).\")\n",
        "    print(\"-\" * 60)\n",
        "\n",
        "# --- Define models ---\n",
        "model_specs = {\n",
        "    \"Model 1: Species Richness\": {\"y\": \"species_richness\", \"X\": [\"estimate\", \"plot_count\"]},\n",
        "    \"Model 2: Threatened/Endangered\": {\"y\": \"count_te_species\", \"X\": [\"estimate\", \"plot_count\"]},\n",
        "    \"Model 3: Species Richness w/ Year\": {\"y\": \"species_richness\", \"X\": [\"estimate\", \"plot_count\", \"inventory_year\"]},\n",
        "    \"Model 4: Threatened/Endangered w/ Year\": {\"y\": \"count_te_species\", \"X\": [\"estimate\", \"plot_count\", \"inventory_year\"]}\n",
        "}\n",
        "\n",
        "# --- Fit models and print summaries ---\n",
        "for name, specs in model_specs.items():\n",
        "    print(f\"\\n=== {name} ===\")\n",
        "    model = fit_model(specs[\"y\"], specs[\"X\"], df)\n",
        "    print(model.summary())\n",
        "    interpret_model(model, specs[\"y\"])\n",
        "\n",
        "# --- Visualize key relationships ---\n",
        "sns.set(style=\"whitegrid\")\n",
        "\n",
        "plt.figure(figsize=(7,5))\n",
        "sns.regplot(data=df, x='estimate', y='species_richness', line_kws={'color':'blue'})\n",
        "plt.title(\"Forest Area Change vs Species Richness\")\n",
        "plt.xlabel(\"Forest Area Estimate\")\n",
        "plt.ylabel(\"Species Richness\")\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(7,5))\n",
        "sns.regplot(data=df, x='estimate', y='count_te_species', line_kws={'color':'darkred'})\n",
        "plt.title(\"Forest Area Change vs Threatened/Endangered Species\")\n",
        "plt.xlabel(\"Forest Area Estimate\")\n",
        "plt.ylabel(\"Threatened/Endangered Species Count\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "BbvxgnX66yiW",
      "metadata": {
        "id": "BbvxgnX66yiW"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "crcmfkoyYH-O",
      "metadata": {
        "id": "crcmfkoyYH-O"
      },
      "source": [
        "##Interpretations and Model Summary Notes\n",
        "model 1 (species richness)<br>\n",
        "- Slight evidence that higher deforestation (larger estimate) is associated with lower species richness.\n",
        "- Plot sampling effort doesn’t significantly affect species richness here.\n",
        "- Overall model explains very little of the variation, so other unmeasured factors (habitat type, climate, management) are likely more important.\n",
        "- The negative effect of deforestation is small in magnitude but statistically detectable. This suggests deforestation may be affecting biodiversity, even if the model overall is weak. <br><br>\n",
        "model 2 (te species)<br>\n",
        "- No statistically significant relationship between deforestation and the number of threatened/endangered species.\n",
        "- Suggests that, based on this data, other factors besides plot-level deforestation estimates are more important in determining counts of threatened species.\n",
        "- Could be due to small sample size, low variation, or lag effects (threatened species respond to habitat loss over longer timescales). <br><br>\n",
        "\n",
        "model 3 (species richness w/ inventory year) <br>\n",
        "- Time is the dominant factor: species richness is decreasing by ~296 species per year on average.\n",
        "- Deforestation estimate and plot count are not statistically significant when controlling for year.\n",
        "- This suggests a temporal decline in biodiversity, possibly reflecting ongoing habitat loss, climate change, or cumulative environmental pressures.\n",
        "- The large condition number (2.44e8) indicates potential numerical instability, so coefficients for other predictors (estimate, plot_count) should be interpreted cautiously. <br><br>\n",
        "\n",
        "model 4 (te species w/ inventory year) <br>\n",
        "- The number of threatened/endangered species is decreasing over time (~2 species per year).\n",
        "- Deforestation estimate and plot count are not significant here either.\n",
        "- Suggests that temporal trends (long-term declines) are more important than plot-level deforestation in explaining endangered species counts.\n",
        "- Low R² indicates that most variation is unexplained—other environmental, ecological, or management variables may be key."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "LRXroINcTVIO",
      "metadata": {
        "id": "LRXroINcTVIO"
      },
      "source": [
        "##Models 5/6 - newer"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5N_YxEP5VaEP",
      "metadata": {
        "id": "5N_YxEP5VaEP"
      },
      "source": [
        "###Model 5\n",
        "- Identify which biodiversity characteristics (species, nativeness, conservation status diversity) predict deforestation intensity at the state level."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "kYTsZXbcSs5h",
      "metadata": {
        "id": "kYTsZXbcSs5h"
      },
      "outputs": [],
      "source": [
        "#Identify which biodiversity characteristics (species, nativeness, conservation status diversity)\n",
        "#predict deforestation intensity at the state level.\n",
        "import statsmodels.api as sm\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "# --- Copy and clean ---\n",
        "df = merged_final.copy()\n",
        "\n",
        "# Ensure numeric\n",
        "for col in [\"estimate\", \"species_richness\", \"count_te_species\", \"plot_count\", \"inventory_year\"]:\n",
        "    df[col] = pd.to_numeric(df[col], errors=\"coerce\")\n",
        "\n",
        "# Drop missing\n",
        "df = df.dropna(subset=[\"estimate\", \"species_richness\", \"count_te_species\", \"plot_count\", \"inventory_year\"])\n",
        "\n",
        "# --- Model 5: Ecosystem Vulnerability Model ---\n",
        "y = df[\"estimate\"]\n",
        "X = df[[\"species_richness\", \"count_te_species\", \"plot_count\", \"inventory_year\"]]\n",
        "X = sm.add_constant(X)\n",
        "\n",
        "model_5 = sm.OLS(y, X).fit()\n",
        "print(model_5.summary())\n",
        "\n",
        "# --- Interpretation ---\n",
        "print(\"\\n📊 INTERPRETATION: Ecosystem Vulnerability Model\")\n",
        "for var, coef, p in zip(model_5.params.index, model_5.params.values, model_5.pvalues.values):\n",
        "    if var == \"const\":\n",
        "        continue\n",
        "    sig = \"✅ Significant\" if p < 0.05 else \"❌ Not significant\"\n",
        "    direction = \"↑ increases\" if coef > 0 else \"↓ decreases\"\n",
        "    print(f\"- {var}: {direction} deforestation (coef={coef:.4f}, p={p:.4f}) → {sig}\")\n",
        "\n",
        "# --- Visualization ---\n",
        "sns.set(style=\"whitegrid\")\n",
        "plt.figure(figsize=(7,5))\n",
        "sns.regplot(data=df, x=\"species_richness\", y=\"estimate\", line_kws={\"color\":\"green\"})\n",
        "plt.title(\"Species Richness vs Deforestation Estimate (Model 5)\")\n",
        "plt.xlabel(\"Species Richness\")\n",
        "plt.ylabel(\"Deforestation Estimate\")\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(7,5))\n",
        "sns.regplot(data=df, x=\"count_te_species\", y=\"estimate\", line_kws={\"color\":\"darkred\"})\n",
        "plt.title(\"Threatened Species vs Deforestation Estimate (Model 5)\")\n",
        "plt.xlabel(\"Threatened/Endangered Species Count\")\n",
        "plt.ylabel(\"Deforestation Estimate\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "YeBVoznYVUMO",
      "metadata": {
        "id": "YeBVoznYVUMO"
      },
      "source": [
        "####model 5 interpretations\n",
        "- P value of plot_counts is <.05 which means its strong. States with more FIA plots (sampling intensity or land area) show higher estimated deforestation. This likely reflects larger or more forested states having more plots and, naturally, higher total forest loss."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Ep5j-okV0eB1",
      "metadata": {
        "id": "Ep5j-okV0eB1"
      },
      "source": [
        "####Model Diagnostics and Consistency Checks (by Aruba)\n",
        "- After Bianca’s regression models were created, I ran additional diagnostic tests to ensure the models were stable and residuals followed a normal pattern.\n",
        "These plots help verify that the regression assumptions hold true and the models’ trends are consistent."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "38w-oRpvHAu2",
      "metadata": {
        "id": "38w-oRpvHAu2"
      },
      "outputs": [],
      "source": [
        "!pip install gdown\n",
        "\n",
        "# Download your datasets from Google Drive again\n",
        "!gdown 1g3IRypHA2EUwWaAkyD_-n7RzfLSJuXD5 -O parks.csv\n",
        "!gdown 1Ya4KF7cCkYF7uRs67VNnGpJillBhA8e1 -O species.csv\n",
        "!gdown 167-iGjrX0ox87N5eXVt-q_jzhtNsKQDY -O deforestation.csv\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "KtoZ5AkLHNNS",
      "metadata": {
        "id": "KtoZ5AkLHNNS"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "\n",
        "# Load datasets\n",
        "parks = pd.read_csv(\"parks.csv\")\n",
        "species = pd.read_csv(\"species.csv\")\n",
        "deforestation = pd.read_csv(\"deforestation.csv\")\n",
        "\n",
        "# --- Merge and prepare biodiversity summary ---\n",
        "state_lookup = {\n",
        "    \"AL\": \"Alabama\", \"AK\": \"Alaska\", \"AZ\": \"Arizona\", \"AR\": \"Arkansas\", \"CA\": \"California\",\n",
        "    \"CO\": \"Colorado\", \"CT\": \"Connecticut\", \"DE\": \"Delaware\", \"FL\": \"Florida\", \"GA\": \"Georgia\",\n",
        "    \"HI\": \"Hawaii\", \"ID\": \"Idaho\", \"IL\": \"Illinois\", \"IN\": \"Indiana\", \"IA\": \"Iowa\",\n",
        "    \"KS\": \"Kansas\", \"KY\": \"Kentucky\", \"LA\": \"Louisiana\", \"ME\": \"Maine\", \"MD\": \"Maryland\",\n",
        "    \"MA\": \"Massachusetts\", \"MI\": \"Michigan\", \"MN\": \"Minnesota\", \"MS\": \"Mississippi\",\n",
        "    \"MO\": \"Missouri\", \"MT\": \"Montana\", \"NE\": \"Nebraska\", \"NV\": \"Nevada\", \"NH\": \"New Hampshire\",\n",
        "    \"NJ\": \"New Jersey\", \"NM\": \"New Mexico\", \"NY\": \"New York\", \"NC\": \"North Carolina\",\n",
        "    \"ND\": \"North Dakota\", \"OH\": \"Ohio\", \"OK\": \"Oklahoma\", \"OR\": \"Oregon\", \"PA\": \"Pennsylvania\",\n",
        "    \"RI\": \"Rhode Island\", \"SC\": \"South Carolina\", \"SD\": \"South Dakota\", \"TN\": \"Tennessee\",\n",
        "    \"TX\": \"Texas\", \"UT\": \"Utah\", \"VT\": \"Vermont\", \"VA\": \"Virginia\", \"WA\": \"Washington\",\n",
        "    \"WV\": \"West Virginia\", \"WI\": \"Wisconsin\", \"WY\": \"Wyoming\"\n",
        "}\n",
        "\n",
        "species = species.merge(parks[[\"Park Name\", \"State\"]], on=\"Park Name\", how=\"left\")\n",
        "species[\"State_Name\"] = species[\"State\"].map(state_lookup)\n",
        "\n",
        "# Native species richness\n",
        "native_species = species[species[\"Nativeness\"] == \"Native\"]\n",
        "species_richness = (\n",
        "    native_species.groupby(\"State_Name\")[\"Species ID\"].nunique().reset_index()\n",
        ")\n",
        "species_richness.rename(columns={\"Species ID\": \"species_richness\"}, inplace=True)\n",
        "\n",
        "# Threatened/endangered species count\n",
        "te_statuses = [\"Threatened\", \"Proposed Endangered\", \"Proposed Threatened\", \"Endangered\"]\n",
        "te_species = species[species[\"Conservation Status\"].isin(te_statuses)]\n",
        "count_te_species = te_species.groupby(\"State_Name\")[\"Species ID\"].nunique().reset_index()\n",
        "count_te_species.rename(columns={\"Species ID\": \"count_te_species\"}, inplace=True)\n",
        "\n",
        "# Merge biodiversity summaries\n",
        "species_summary = pd.merge(species_richness, count_te_species, on=\"State_Name\", how=\"outer\")\n",
        "\n",
        "# Clean and merge\n",
        "deforestation[\"State_Name\"] = deforestation[\"STATE_CODE\"].apply(lambda x: re.sub(r'^\\d+\\s+', '', str(x)))\n",
        "deforestation[\"State_Name_clean\"] = deforestation[\"State_Name\"].str.strip().str.lower()\n",
        "species_summary[\"State_Name_clean\"] = species_summary[\"State_Name\"].str.strip().str.lower()\n",
        "\n",
        "final = pd.merge(deforestation, species_summary, on=\"State_Name_clean\", how=\"left\")\n",
        "\n",
        "print(\"✅ Final dataset ready!\")\n",
        "print(final.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2_gNF8VZHjcP",
      "metadata": {
        "id": "2_gNF8VZHjcP"
      },
      "outputs": [],
      "source": [
        "df = final.copy()\n",
        "...\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "VijJFEIAWAx2",
      "metadata": {
        "id": "VijJFEIAWAx2"
      },
      "source": [
        "###Model 6\n",
        "- Examining how biodiversity and park size affect deforestation patterns"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "lN4-IMYeWjHz",
      "metadata": {
        "id": "lN4-IMYeWjHz"
      },
      "source": [
        "####model 6 interpretation\n",
        "- this kind of confirmed that plot_count is the only variable with significance. Looking at inventory year there was no significance, and so since model 5, plot_count is still the only one we have that shows any correlation to estimate.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "uoijn5w1UG95",
      "metadata": {
        "id": "uoijn5w1UG95"
      },
      "source": [
        "#### Model 6 Diagnostics and Validation (by Aruba )\n",
        "\n",
        "After Bianca developed the Protected Area Effectiveness Model (Model 6), I validated its reliability by running diagnostic tests and verifying regression assumptions.\n",
        "These plots check whether the residuals are normally distributed and if the model behaves consistently across fitted values.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "CciDg1F5tZoD",
      "metadata": {
        "id": "CciDg1F5tZoD"
      },
      "outputs": [],
      "source": [
        "# --- Download datasets directly from Google Drive (team links) ---\n",
        "!pip install -q gdown\n",
        "\n",
        "# Download files\n",
        "!gdown 1g3IRypHA2EUwWaAkyD_-n7RzfLSJuXD5 -O parks.csv\n",
        "!gdown 1Ya4KF7cCkYF7uRs67VNnGpJillBhA8e1 -O species.csv\n",
        "!gdown 167-iGjrX0ox87N5eXVt-q_jzhtNsKQDY -O deforestation.csv\n",
        "\n",
        "# Confirm files are in the workspace\n",
        "import os\n",
        "print(os.listdir())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "lgOpzoas4jMv",
      "metadata": {
        "id": "lgOpzoas4jMv"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "parks = pd.read_csv(\"parks.csv\", low_memory=False)\n",
        "species = pd.read_csv(\"species.csv\", low_memory=False)\n",
        "deforestation = pd.read_csv(\"deforestation.csv\", low_memory=False)\n",
        "\n",
        "print(\"Parks columns:\", list(parks.columns))\n",
        "print(\"Species columns:\", list(species.columns))\n",
        "print(\"Deforestation columns:\", list(deforestation.columns))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c-NCGdUg6-NP",
      "metadata": {
        "id": "c-NCGdUg6-NP"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import statsmodels.api as sm\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# Step 1 – Load datasets safely\n",
        "# ------------------------------------------------------------\n",
        "parks = pd.read_csv(\"parks.csv\", low_memory=False)\n",
        "species = pd.read_csv(\"species.csv\", low_memory=False)\n",
        "deforestation = pd.read_csv(\"deforestation.csv\", low_memory=False)\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# Step 2 – Clean and prepare\n",
        "# ------------------------------------------------------------\n",
        "parks.columns = parks.columns.str.lower().str.strip()\n",
        "species.columns = species.columns.str.lower().str.strip()\n",
        "deforestation.columns = deforestation.columns.str.lower().str.strip()\n",
        "\n",
        "# Convert acres to numeric\n",
        "parks[\"acres\"] = pd.to_numeric(parks[\"acres\"], errors=\"coerce\")\n",
        "\n",
        "# Aggregate total protected acres by state\n",
        "state_acres = (\n",
        "    parks.groupby(\"state\", as_index=False)[\"acres\"]\n",
        "    .sum()\n",
        "    .rename(columns={\"acres\": \"total_protected_acres\"})\n",
        ")\n",
        "\n",
        "# Standardize deforestation column names\n",
        "deforestation = deforestation.rename(\n",
        "    columns={\n",
        "        \"inventory_year\": \"year\",\n",
        "        \"state_code\": \"state\",\n",
        "        \"estimate\": \"estimate\",\n",
        "        \"plot_count\": \"plot_count\"\n",
        "    }\n",
        ")\n",
        "\n",
        "# Merge on state\n",
        "df = deforestation.merge(state_acres, on=\"state\", how=\"left\")\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# Step 3 – Convert everything to numeric & clean\n",
        "# ------------------------------------------------------------\n",
        "for col in [\"estimate\", \"plot_count\", \"total_protected_acres\", \"year\"]:\n",
        "    df[col] = pd.to_numeric(df[col], errors=\"coerce\")\n",
        "\n",
        "df = df.dropna(subset=[\"estimate\", \"plot_count\", \"total_protected_acres\", \"year\"])\n",
        "df = df[df[\"plot_count\"] > 0]\n",
        "\n",
        "print(\"Rows available after cleaning:\", len(df))\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# Step 4 – Fit model only if data exists\n",
        "# ------------------------------------------------------------\n",
        "if len(df) >= 5:\n",
        "    X = df[[\"plot_count\", \"year\", \"total_protected_acres\"]]\n",
        "    y = df[\"estimate\"]\n",
        "\n",
        "    # Ensure numeric arrays\n",
        "    X = X.apply(pd.to_numeric, errors=\"coerce\")\n",
        "    y = pd.to_numeric(y, errors=\"coerce\")\n",
        "\n",
        "    X = sm.add_constant(X, has_constant=\"add\")\n",
        "\n",
        "    model_6 = sm.OLS(y, X, missing=\"drop\").fit()\n",
        "    print(model_6.summary())\n",
        "\n",
        "    # --------------------------------------------------------\n",
        "    # Step 5 – Diagnostics\n",
        "    # --------------------------------------------------------\n",
        "    residuals = model_6.resid\n",
        "    fitted = model_6.fittedvalues\n",
        "\n",
        "    # Residuals vs Fitted\n",
        "    plt.figure(figsize=(6, 4))\n",
        "    sns.scatterplot(x=fitted, y=residuals)\n",
        "    plt.axhline(0, color=\"red\", linestyle=\"--\")\n",
        "    plt.title(\"Model 6: Residuals vs Fitted Values\")\n",
        "    plt.xlabel(\"Fitted Values\")\n",
        "    plt.ylabel(\"Residuals\")\n",
        "    plt.show()\n",
        "\n",
        "    # Q–Q Plot\n",
        "    sm.qqplot(residuals, line=\"s\")\n",
        "    plt.title(\"Model 6: Q–Q Plot of Residuals\")\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"Not enough valid numeric data to fit Model 6.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "sqPgWVON_-vy",
      "metadata": {
        "id": "sqPgWVON_-vy"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import statsmodels.api as sm\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Step 1 – Load datasets\n",
        "parks = pd.read_csv(\"parks.csv\", low_memory=False)\n",
        "species = pd.read_csv(\"species.csv\", low_memory=False)\n",
        "deforestation = pd.read_csv(\"deforestation.csv\", low_memory=False)\n",
        "\n",
        "# Step 2 – Normalize column names\n",
        "parks.columns = parks.columns.str.lower().str.strip()\n",
        "deforestation.columns = deforestation.columns.str.lower().str.strip()\n",
        "\n",
        "# Step 3 – Extract clean state names from deforestation\n",
        "deforestation[\"state_name\"] = (\n",
        "    deforestation[\"state_code\"]\n",
        "    .astype(str)\n",
        "    .str.replace(r\"^\\d+\\s*\", \"\", regex=True)   # remove numbers like \"12 \"\n",
        "    .str.strip()\n",
        ")\n",
        "\n",
        "# Step 4 – Map full names to abbreviations\n",
        "name_to_abbr = {\n",
        "    \"Alabama\":\"AL\",\"Alaska\":\"AK\",\"Arizona\":\"AZ\",\"Arkansas\":\"AR\",\"California\":\"CA\",\n",
        "    \"Colorado\":\"CO\",\"Connecticut\":\"CT\",\"Delaware\":\"DE\",\"Florida\":\"FL\",\"Georgia\":\"GA\",\n",
        "    \"Hawaii\":\"HI\",\"Idaho\":\"ID\",\"Illinois\":\"IL\",\"Indiana\":\"IN\",\"Iowa\":\"IA\",\"Kansas\":\"KS\",\n",
        "    \"Kentucky\":\"KY\",\"Louisiana\":\"LA\",\"Maine\":\"ME\",\"Maryland\":\"MD\",\"Massachusetts\":\"MA\",\n",
        "    \"Michigan\":\"MI\",\"Minnesota\":\"MN\",\"Mississippi\":\"MS\",\"Missouri\":\"MO\",\"Montana\":\"MT\",\n",
        "    \"Nebraska\":\"NE\",\"Nevada\":\"NV\",\"New Hampshire\":\"NH\",\"New Jersey\":\"NJ\",\"New Mexico\":\"NM\",\n",
        "    \"New York\":\"NY\",\"North Carolina\":\"NC\",\"North Dakota\":\"ND\",\"Ohio\":\"OH\",\"Oklahoma\":\"OK\",\n",
        "    \"Oregon\":\"OR\",\"Pennsylvania\":\"PA\",\"Rhode Island\":\"RI\",\"South Carolina\":\"SC\",\n",
        "    \"South Dakota\":\"SD\",\"Tennessee\":\"TN\",\"Texas\":\"TX\",\"Utah\":\"UT\",\"Vermont\":\"VT\",\n",
        "    \"Virginia\":\"VA\",\"Washington\":\"WA\",\"West Virginia\":\"WV\",\"Wisconsin\":\"WI\",\"Wyoming\":\"WY\"\n",
        "}\n",
        "deforestation[\"state_abbr\"] = deforestation[\"state_name\"].map(name_to_abbr)\n",
        "\n",
        "# Step 5 – Detect the correct year column\n",
        "year_col = [c for c in deforestation.columns if \"year\" in c][0]\n",
        "print(\"Detected year column:\", year_col)\n",
        "\n",
        "# Step 6 – Convert numeric columns safely\n",
        "for col in [\"estimate\", \"plot_count\", \"variance\", \"se\", \"se_percent\"]:\n",
        "    if col in deforestation.columns:\n",
        "        deforestation[col] = pd.to_numeric(deforestation[col], errors=\"coerce\")\n",
        "\n",
        "# Step 7 – Clean and aggregate parks data\n",
        "parks[\"acres\"] = pd.to_numeric(parks[\"acres\"], errors=\"coerce\")\n",
        "parks_state = parks.groupby(\"state\", as_index=False)[\"acres\"].sum()\n",
        "parks_state.rename(columns={\"acres\": \"total_protected_acres\"}, inplace=True)\n",
        "\n",
        "# Step 8 – Merge datasets using abbreviations\n",
        "df = deforestation.merge(parks_state, left_on=\"state_abbr\", right_on=\"state\", how=\"left\")\n",
        "\n",
        "# Step 9 – Drop invalid or missing data\n",
        "df = df.dropna(subset=[\"estimate\", \"plot_count\", \"total_protected_acres\", year_col])\n",
        "df = df[df[\"plot_count\"] > 0]\n",
        "print(\"Rows available after cleaning:\", len(df))\n",
        "\n",
        "# Step 10 – Fit Model 6 (final fix)\n",
        "if len(df) >= 5:\n",
        "    X = df[[\"plot_count\", year_col, \"total_protected_acres\"]].copy()\n",
        "    y = df[\"estimate\"].copy()\n",
        "\n",
        "    # Convert all to numeric\n",
        "    X = X.apply(pd.to_numeric, errors=\"coerce\")\n",
        "    y = pd.to_numeric(y, errors=\"coerce\")\n",
        "\n",
        "    # Drop rows with NaN\n",
        "    valid_idx = X.dropna().index.intersection(y.dropna().index)\n",
        "    X = X.loc[valid_idx]\n",
        "    y = y.loc[valid_idx]\n",
        "\n",
        "    # Add constant\n",
        "    X = sm.add_constant(X)\n",
        "\n",
        "    # Fit OLS model\n",
        "    model_6 = sm.OLS(y, X).fit()\n",
        "    print(model_6.summary())\n",
        "\n",
        "    # --- Diagnostics ---\n",
        "    residuals = model_6.resid\n",
        "    fitted = model_6.fittedvalues\n",
        "\n",
        "    plt.figure(figsize=(6, 4))\n",
        "    sns.scatterplot(x=fitted, y=residuals)\n",
        "    plt.axhline(0, color=\"red\", linestyle=\"--\")\n",
        "    plt.title(\"Model 6: Residuals vs Fitted Values\")\n",
        "    plt.xlabel(\"Fitted Values\")\n",
        "    plt.ylabel(\"Residuals\")\n",
        "    plt.show()\n",
        "\n",
        "    sm.qqplot(residuals, line=\"s\")\n",
        "    plt.title(\"Model 6: Q–Q Plot of Residuals\")\n",
        "    plt.show()\n",
        "\n",
        "else:\n",
        "    print(\"Not enough valid numeric data to fit Model 6 even after correction.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "jE3_Hn5x8RIp",
      "metadata": {
        "id": "jE3_Hn5x8RIp"
      },
      "outputs": [],
      "source": [
        "print(\"Unique states in parks.csv:\", parks[\"state\"].unique()[:10])\n",
        "print(\"Unique state codes in deforestation.csv:\", deforestation[\"state_code\"].unique()[:10])\n",
        "print(\"Deforestation numeric preview:\")\n",
        "print(deforestation[[\"state_code\", \"estimate\", \"plot_count\", \"inventory_year\"]].head())\n",
        "print(\"Park acres preview:\")\n",
        "print(parks[[\"state\", \"acres\"]].head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "YtXQXSwsarWg",
      "metadata": {
        "id": "YtXQXSwsarWg"
      },
      "outputs": [],
      "source": [
        "# import pandas as pd\n",
        "# import statsmodels.api as sm\n",
        "\n",
        "# # clean and standardize parks.csv states\n",
        "# parks = pd.read_csv(\"parks.csv\")\n",
        "\n",
        "# # Split multi-state parks into separate rows\n",
        "# parks_clean = parks.copy()\n",
        "# parks_clean = parks_clean.assign(State=parks_clean[\"State\"].str.split(r\",\\s*\")).explode(\"State\")\n",
        "# parks_clean[\"State\"] = parks_clean[\"State\"].str.strip()\n",
        "\n",
        "# # Map abbreviations to full state names manually\n",
        "# abbr_to_name = {\n",
        "#     \"AL\":\"Alabama\",\"AK\":\"Alaska\",\"AZ\":\"Arizona\",\"AR\":\"Arkansas\",\"CA\":\"California\",\n",
        "#     \"CO\":\"Colorado\",\"CT\":\"Connecticut\",\"DE\":\"Delaware\",\"FL\":\"Florida\",\"GA\":\"Georgia\",\n",
        "#     \"HI\":\"Hawaii\",\"ID\":\"Idaho\",\"IL\":\"Illinois\",\"IN\":\"Indiana\",\"IA\":\"Iowa\",\"KS\":\"Kansas\",\n",
        "#     \"KY\":\"Kentucky\",\"LA\":\"Louisiana\",\"ME\":\"Maine\",\"MD\":\"Maryland\",\"MA\":\"Massachusetts\",\n",
        "#     \"MI\":\"Michigan\",\"MN\":\"Minnesota\",\"MS\":\"Mississippi\",\"MO\":\"Missouri\",\"MT\":\"Montana\",\n",
        "#     \"NE\":\"Nebraska\",\"NV\":\"Nevada\",\"NH\":\"New Hampshire\",\"NJ\":\"New Jersey\",\"NM\":\"New Mexico\",\n",
        "#     \"NY\":\"New York\",\"NC\":\"North Carolina\",\"ND\":\"North Dakota\",\"OH\":\"Ohio\",\"OK\":\"Oklahoma\",\n",
        "#     \"OR\":\"Oregon\",\"PA\":\"Pennsylvania\",\"RI\":\"Rhode Island\",\"SC\":\"South Carolina\",\n",
        "#     \"SD\":\"South Dakota\",\"TN\":\"Tennessee\",\"TX\":\"Texas\",\"UT\":\"Utah\",\"VT\":\"Vermont\",\n",
        "#     \"VA\":\"Virginia\",\"WA\":\"Washington\",\"WV\":\"West Virginia\",\"WI\":\"Wisconsin\",\"WY\":\"Wyoming\"\n",
        "# }\n",
        "# parks_clean[\"State\"] = parks_clean[\"State\"].map(abbr_to_name)\n",
        "\n",
        "# # Drop rows where state mapping failed\n",
        "# parks_clean = parks_clean.dropna(subset=[\"State\"])\n",
        "\n",
        "# # Convert Acres to numeric\n",
        "# parks_clean[\"Acres\"] = pd.to_numeric(parks_clean[\"Acres\"], errors=\"coerce\")\n",
        "# parks_clean = parks_clean.dropna(subset=[\"Acres\"])\n",
        "\n",
        "# # Aggregate total protected acres per state\n",
        "# state_acres = parks_clean.groupby(\"State\", as_index=False)[\"Acres\"].sum()\n",
        "# state_acres.rename(columns={\"Acres\": \"total_protected_acres\"}, inplace=True)\n",
        "\n",
        "# # clean and standardize deforesation states\n",
        "# df = final.copy()  # your main dataset\n",
        "\n",
        "# # Standardize state names\n",
        "# df[\"state_name_clean\"] = df[\"state_name_clean\"].str.strip().str.title()\n",
        "\n",
        "# # Merge total protected acres\n",
        "# df = df.merge(state_acres[[\"State\", \"total_protected_acres\"]],\n",
        "#               how=\"left\", left_on=\"state_name_clean\", right_on=\"State\")\n",
        "\n",
        "# # Drop State column if exists\n",
        "# if \"State\" in df.columns:\n",
        "#     df = df.drop(columns=[\"State\"])\n",
        "\n",
        "# # Fill missing protected acres with 0\n",
        "# df[\"total_protected_acres\"] = df[\"total_protected_acres\"].fillna(0)\n",
        "\n",
        "# # prepare data\n",
        "# X6 = df[[\n",
        "#     \"species_richness\",\n",
        "#     \"count_te_species\",\n",
        "#     \"plot_count\",\n",
        "#     \"inventory_year\",\n",
        "#     \"total_protected_acres\"\n",
        "# ]].copy()\n",
        "# y6 = df[\"estimate\"]\n",
        "\n",
        "# # Ensure numeric\n",
        "# X6[\"inventory_year\"] = pd.to_numeric(X6[\"inventory_year\"], errors=\"coerce\")\n",
        "# X6 = X6.dropna()\n",
        "# y6 = y6.loc[X6.index]\n",
        "\n",
        "# # Add constant term\n",
        "# X6 = sm.add_constant(X6)\n",
        "\n",
        "# #fit the model\n",
        "# model_6 = sm.OLS(y6, X6).fit()\n",
        "# print(model_6.summary())\n",
        "\n",
        "# #visual\n",
        "# print(\"\\n📊 INTERPRETATION: Protected Area Effectiveness Model (with acreage)\")\n",
        "# print(\"- species_richness: biodiversity effect on forest change\")\n",
        "# print(\"- count_te_species: threatened/endangered species impact\")\n",
        "# print(\"- plot_count: sampling effort\")\n",
        "# print(\"- inventory_year: temporal trend\")\n",
        "# print(\"- total_protected_acres: impact of protected land area on deforestation\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5WF2DtQ8C2KN",
      "metadata": {
        "id": "5WF2DtQ8C2KN"
      },
      "source": [
        "##weather models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "YxkFbbfwzcRa",
      "metadata": {
        "id": "YxkFbbfwzcRa"
      },
      "outputs": [],
      "source": [
        "#just to see column names again\n",
        "print(\"weather_multi:\", weather.columns.tolist())\n",
        "print(\"species:\", species.columns.tolist())\n",
        "print(\"parks:\", parks.columns.tolist())\n",
        "print(\"deforestation:\", deforestation.columns.tolist())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "PYkWfZLuD-mm",
      "metadata": {
        "id": "PYkWfZLuD-mm"
      },
      "source": [
        "###hypothesis 7-10\n",
        "- 7 incorporates temperature versus biodiversity\n",
        "- 8 is temperature versus park size\n",
        "- 9 is temperature versus deforestation effects(estimate as percentage decrease per year)\n",
        "- 10 is everything (biodiversity, park size, deforestation effects (estimate as percentage decrease per year))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "rJdfg-R0C6kc",
      "metadata": {
        "id": "rJdfg-R0C6kc"
      },
      "outputs": [],
      "source": [
        "# --- Hypothesis Analysis Including Weather, Parks, and Deforestation ---\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import pingouin as pg\n",
        "import us\n",
        "\n",
        "# --- 0. Normalize state column names across datasets ---\n",
        "# Make sure all datasets use a consistent 'State' column\n",
        "weather.rename(columns={\"state\": \"State\"}, inplace=True)\n",
        "parks.rename(columns={\"state\": \"State\"}, inplace=True)\n",
        "deforestation.rename(columns={\"state_abbr\": \"State\"}, inplace=True)\n",
        "\n",
        "# --- 1. Prepare Weather Data (2019–2022) ---\n",
        "weather_multi = weather[(weather[\"year\"] >= 2019) & (weather[\"year\"] <= 2022)].copy()\n",
        "\n",
        "# Convert state names to 2-letter abbreviations if needed\n",
        "weather_multi[\"State\"] = weather_multi[\"State\"].map(\n",
        "    lambda x: us.states.lookup(x).abbr if us.states.lookup(x) else x\n",
        ")\n",
        "\n",
        "# Compute average temperature per state\n",
        "temp_state_multi = (\n",
        "    weather_multi.groupby(\"State\")[\"average_temp\"]\n",
        "    .mean()\n",
        "    .reset_index()\n",
        "    .rename(columns={\"average_temp\": \"Avg_Temp_2019_2022\"})\n",
        ")\n",
        "\n",
        "# --- 2. Merge with Biodiversity Data ---\n",
        "bio_climate = biodiversity_state.merge(temp_state_multi, on=\"State\", how=\"left\")\n",
        "\n",
        "# --- 3. Merge Park Size Data ---\n",
        "acres_state = parks.groupby(\"State\")[\"acres\"].mean().reset_index().rename(columns={\"acres\": \"Acres\"})\n",
        "bio_climate = bio_climate.merge(acres_state, on=\"State\", how=\"left\")\n",
        "\n",
        "# --- 4. Merge Deforestation Data (latest year per state) ---\n",
        "deforestation_state_latest = deforestation.loc[\n",
        "    deforestation.groupby(\"State\")[\"inventory_year\"].idxmax()\n",
        "][[\"State\", \"estimate\"]].rename(columns={\"estimate\": \"Deforestation_Rate\"})\n",
        "\n",
        "bio_climate = bio_climate.merge(deforestation_state_latest, on=\"State\", how=\"left\")\n",
        "\n",
        "# --- 5. Drop missing values for key variables ---\n",
        "bio_climate = bio_climate.dropna(subset=[\"Avg_Temp_2019_2022\", \"Unique_Species\"])\n",
        "\n",
        "# --- H7: Temperature vs Biodiversity ---\n",
        "h6_model = pg.linear_regression(\n",
        "    bio_climate[[\"Avg_Temp_2019_2022\"]],\n",
        "    bio_climate[\"Unique_Species\"]\n",
        ")\n",
        "print(\"H7: Linear Regression — Temperature vs Biodiversity\")\n",
        "display(h6_model)\n",
        "\n",
        "sns.regplot(x=\"Avg_Temp_2019_2022\", y=\"Unique_Species\", data=bio_climate, color=\"orange\")\n",
        "plt.title(\"H7: Relationship Between Temperature (2019–2022) and Biodiversity\")\n",
        "plt.xlabel(\"Average Temperature (°F, 2019–2022)\")\n",
        "plt.ylabel(\"Unique Species per State\")\n",
        "plt.show()\n",
        "\n",
        "# --- H8: Temperature × Park Size Interaction ---\n",
        "bio_climate[\"Temp_x_Acres\"] = bio_climate[\"Avg_Temp_2019_2022\"] * bio_climate[\"Acres\"]\n",
        "\n",
        "h7_model = pg.linear_regression(\n",
        "    bio_climate[[\"Avg_Temp_2019_2022\", \"Acres\", \"Temp_x_Acres\"]],\n",
        "    bio_climate[\"Unique_Species\"]\n",
        ")\n",
        "print(\"H8: Interaction Model — Temperature × Park Size\")\n",
        "display(h7_model)\n",
        "\n",
        "plt.figure(figsize=(8,6))\n",
        "sns.scatterplot(\n",
        "    x=\"Avg_Temp_2019_2022\",\n",
        "    y=\"Unique_Species\",\n",
        "    size=\"Acres\",\n",
        "    data=bio_climate,\n",
        "    alpha=0.7,\n",
        "    legend=False\n",
        ")\n",
        "plt.title(\"H8: Temperature vs Biodiversity (Bubble Size = Park Area)\")\n",
        "plt.xlabel(\"Average Temperature (°F, 2019–2022)\")\n",
        "plt.ylabel(\"Unique Species per State\")\n",
        "plt.show()\n",
        "\n",
        "# --- H9: Temperature + Deforestation Regression ---\n",
        "if \"Deforestation_Rate\" in bio_climate.columns:\n",
        "    h8_model = pg.linear_regression(\n",
        "        bio_climate[[\"Avg_Temp_2019_2022\", \"Deforestation_Rate\"]],\n",
        "        bio_climate[\"Unique_Species\"],\n",
        "        remove_na=True\n",
        "    )\n",
        "    print(\"H9: Multiple Regression — Temperature + Deforestation\")\n",
        "    display(h8_model)\n",
        "\n",
        "    bio_climate[\"Deforestation_Rate_Norm\"] = (\n",
        "        bio_climate[\"Deforestation_Rate\"] - bio_climate[\"Deforestation_Rate\"].min()\n",
        "    ) / (bio_climate[\"Deforestation_Rate\"].max() - bio_climate[\"Deforestation_Rate\"].min())\n",
        "\n",
        "    sns.lmplot(\n",
        "        x=\"Avg_Temp_2019_2022\",\n",
        "        y=\"Unique_Species\",\n",
        "        hue=\"Deforestation_Rate_Norm\",\n",
        "        data=bio_climate,\n",
        "        palette=\"coolwarm\",\n",
        "        aspect=1.3\n",
        "    )\n",
        "    plt.title(\"H9: Biodiversity vs Temperature by Deforestation Rate\")\n",
        "    plt.xlabel(\"Average Temperature (°F, 2019–2022)\")\n",
        "    plt.ylabel(\"Unique Species per State\")\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"⚠️ H9 skipped — Deforestation data not available.\")\n",
        "\n",
        "# --- H10: Full Multiple Regression Model ---\n",
        "predictors = [\"Avg_Temp_2019_2022\", \"Acres\"]\n",
        "if \"Deforestation_Rate\" in bio_climate.columns:\n",
        "    predictors.append(\"Deforestation_Rate\")\n",
        "\n",
        "h9_model = pg.linear_regression(\n",
        "    bio_climate[predictors],\n",
        "    bio_climate[\"Unique_Species\"],\n",
        "    remove_na=True\n",
        ")\n",
        "print(\"H10: Full Multiple Linear Regression Model\")\n",
        "display(h9_model)\n",
        "\n",
        "plt.figure(figsize=(8,6))\n",
        "sns.scatterplot(\n",
        "    x=\"Avg_Temp_2019_2022\",\n",
        "    y=\"Unique_Species\",\n",
        "    size=\"Acres\",\n",
        "    hue=\"Deforestation_Rate\" if \"Deforestation_Rate\" in bio_climate.columns else None,\n",
        "    data=bio_climate,\n",
        "    alpha=0.7,\n",
        "    palette=\"coolwarm\",\n",
        "    legend=\"brief\"\n",
        ")\n",
        "plt.title(\"H10: Combined Effects — Temperature, Park Size, Deforestation\")\n",
        "plt.xlabel(\"Average Temperature (°F, 2019–2022)\")\n",
        "plt.ylabel(\"Unique Species per State\")\n",
        "plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "LKA9Pfa0VMeB",
      "metadata": {
        "id": "LKA9Pfa0VMeB"
      },
      "source": [
        "####interpretation\n",
        "- 7 pvalue showed no significance\n",
        "- 8 showed significance with its p value but the R^2 value was too high\n",
        "- 9 pvalue showed no significance\n",
        "- 10 so there was no real significance between the three values we looked into compared to temperature\n",
        "- from these, it looks like we are going to have to look into new variables compared to temperature"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "euS0pLtV12SW",
      "metadata": {
        "id": "euS0pLtV12SW"
      },
      "source": [
        "###model 11-13"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "oCqM_nOr167e",
      "metadata": {
        "id": "oCqM_nOr167e"
      },
      "outputs": [],
      "source": [
        "# --- H11: Nonlinear Temperature Model (Quadratic) ---\n",
        "import numpy as np\n",
        "\n",
        "# Add squared temperature term\n",
        "bio_climate[\"Temp_Sq\"] = bio_climate[\"Avg_Temp_2019_2022\"] ** 2\n",
        "\n",
        "# Drop any missing values for relevant columns\n",
        "bio_climate_h11 = bio_climate.dropna(subset=[\"Avg_Temp_2019_2022\", \"Temp_Sq\", \"Unique_Species\"])\n",
        "\n",
        "# Run regression\n",
        "h11_model = pg.linear_regression(\n",
        "    bio_climate_h11[[\"Avg_Temp_2019_2022\", \"Temp_Sq\"]],\n",
        "    bio_climate_h11[\"Unique_Species\"],\n",
        "    remove_na=True\n",
        ")\n",
        "\n",
        "print(\"H11: Quadratic Model — Temperature² vs Biodiversity\")\n",
        "display(h11_model)\n",
        "\n",
        "# Plot the curve\n",
        "sns.scatterplot(x=\"Avg_Temp_2019_2022\", y=\"Unique_Species\", data=bio_climate_h11, alpha=0.6)\n",
        "sns.lineplot(\n",
        "    x=np.linspace(bio_climate_h11[\"Avg_Temp_2019_2022\"].min(), bio_climate_h11[\"Avg_Temp_2019_2022\"].max(), 100),\n",
        "    y=h11_model[\"coef\"][0] +\n",
        "      h11_model[\"coef\"][1] * np.linspace(bio_climate_h11[\"Avg_Temp_2019_2022\"].min(), bio_climate_h11[\"Avg_Temp_2019_2022\"].max(), 100) +\n",
        "      h11_model[\"coef\"][2] * np.linspace(bio_climate_h11[\"Avg_Temp_2019_2022\"].min(), bio_climate_h11[\"Avg_Temp_2019_2022\"].max(), 100)**2,\n",
        "    color=\"red\"\n",
        ")\n",
        "plt.title(\"H11: Nonlinear Relationship Between Temperature and Biodiversity\")\n",
        "plt.xlabel(\"Average Temperature (°F, 2019–2022)\")\n",
        "plt.ylabel(\"Unique Species per State\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "u8MHKYYL2KoG",
      "metadata": {
        "id": "u8MHKYYL2KoG"
      },
      "outputs": [],
      "source": [
        "# --- H12: Park Size and Deforestation Effects on Biodiversity ---\n",
        "import pingouin as pg\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Drop missing values for these columns\n",
        "bio_climate_clean = bio_climate.dropna(subset=[\"Acres\", \"Deforestation_Rate\", \"Unique_Species\"])\n",
        "\n",
        "# Multiple regression\n",
        "h12_model = pg.linear_regression(\n",
        "    bio_climate_clean[[\"Acres\", \"Deforestation_Rate\"]],\n",
        "    bio_climate_clean[\"Unique_Species\"]\n",
        ")\n",
        "\n",
        "print(\"H12: Regression — Park Size + Deforestation vs Biodiversity\")\n",
        "display(h12_model)\n",
        "\n",
        "# Visualization\n",
        "plt.figure(figsize=(8,6))\n",
        "sns.scatterplot(\n",
        "    x=\"Acres\",\n",
        "    y=\"Unique_Species\",\n",
        "    hue=\"Deforestation_Rate\",\n",
        "    data=bio_climate_clean,\n",
        "    palette=\"coolwarm\",\n",
        "    size=\"Deforestation_Rate\",\n",
        "    alpha=0.8\n",
        ")\n",
        "plt.title(\"H12: Biodiversity by Park Size and Deforestation Rate\")\n",
        "plt.xlabel(\"Average Park Size (Acres)\")\n",
        "plt.ylabel(\"Unique Species per State\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "svqSq-hu294k",
      "metadata": {
        "id": "svqSq-hu294k"
      },
      "outputs": [],
      "source": [
        "# --- H13: Park Acres vs Threatened/Endangered Species Count ---\n",
        "import pingouin as pg\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import us\n",
        "\n",
        "# Step 1: Identify threatened/endangered statuses\n",
        "te_statuses = [\"Threatened\", \"Proposed Endangered\", \"Proposed Threatened\", \"Endangered\"]\n",
        "\n",
        "# Step 2: Filter species with those statuses\n",
        "te_species = species_parks[species_parks[\"Conservation Status\"].isin(te_statuses)]\n",
        "\n",
        "# Step 3: Count unique species per state (full name)\n",
        "count_te_species = (\n",
        "    te_species.groupby(\"State_Name\")[\"Species ID\"]\n",
        "    .nunique()\n",
        "    .reset_index()\n",
        "    .rename(columns={\"Species ID\": \"count_te_species\"})\n",
        ")\n",
        "\n",
        "# Step 4: Convert full state names to abbreviations for merging\n",
        "count_te_species[\"State\"] = count_te_species[\"State_Name\"].map(\n",
        "    lambda x: us.states.lookup(x).abbr if us.states.lookup(x) else None\n",
        ")\n",
        "\n",
        "# Step 5: Merge into bio_climate using 2-letter abbreviations\n",
        "bio_threat = bio_climate.merge(count_te_species[[\"State\", \"count_te_species\"]], on=\"State\", how=\"left\")\n",
        "\n",
        "# Step 6: Drop missing values\n",
        "bio_threat = bio_threat.dropna(subset=[\"Acres\", \"count_te_species\"])\n",
        "\n",
        "# Step 7: Linear regression\n",
        "h13_model = pg.linear_regression(\n",
        "    bio_threat[[\"Acres\"]],\n",
        "    bio_threat[\"count_te_species\"]\n",
        ")\n",
        "\n",
        "print(\"H13: Linear Regression — Park Acres vs Threatened/Endangered Species Count\")\n",
        "display(h13_model)\n",
        "\n",
        "# Step 8: Visualization\n",
        "sns.regplot(\n",
        "    x=\"Acres\",\n",
        "    y=\"count_te_species\",\n",
        "    data=bio_threat,\n",
        "    color=\"teal\"\n",
        ")\n",
        "plt.title(\"H13: Relationship Between Park Size and Threatened/Endangered Species Count\")\n",
        "plt.xlabel(\"Average Park Size (Acres)\")\n",
        "plt.ylabel(\"Threatened/Endangered Species Count\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "EIikOwov4vUL",
      "metadata": {
        "id": "EIikOwov4vUL"
      },
      "source": [
        "###Models 14-"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "IykFpnzR44eQ",
      "metadata": {
        "id": "IykFpnzR44eQ"
      },
      "outputs": [],
      "source": [
        "# --- H14: Temperature vs Threatened/Endangered Species Count ---\n",
        "\n",
        "bio_temp_te = bio_climate.merge(count_te_species[[\"State\", \"count_te_species\"]], on=\"State\", how=\"left\")\n",
        "bio_temp_te = bio_temp_te.dropna(subset=[\"Avg_Temp_2019_2022\", \"count_te_species\"])\n",
        "\n",
        "h14_model = pg.linear_regression(\n",
        "    bio_temp_te[[\"Avg_Temp_2019_2022\"]],\n",
        "    bio_temp_te[\"count_te_species\"]\n",
        ")\n",
        "\n",
        "print(\"H14: Linear Regression — Temperature vs Threatened/Endangered Species Count\")\n",
        "display(h14_model)\n",
        "\n",
        "sns.regplot(\n",
        "    x=\"Avg_Temp_2019_2022\",\n",
        "    y=\"count_te_species\",\n",
        "    data=bio_temp_te,\n",
        "    color=\"darkred\"\n",
        ")\n",
        "plt.title(\"H14: Relationship Between Temperature and Threatened/Endangered Species Count\")\n",
        "plt.xlabel(\"Average Temperature (°F, 2019–2022)\")\n",
        "plt.ylabel(\"Threatened/Endangered Species Count\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Jy4foVvDzava",
      "metadata": {
        "id": "Jy4foVvDzava"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pingouin as pg\n",
        "\n",
        "# --- Prepare data ---\n",
        "bio_temp_te = bio_climate.merge(count_te_species[[\"State\", \"count_te_species\"]], on=\"State\", how=\"left\")\n",
        "bio_temp_te = bio_temp_te.dropna(subset=[\"Avg_Temp_2019_2022\", \"count_te_species\"])\n",
        "\n",
        "# --- Linear regression ---\n",
        "h14_model = pg.linear_regression(\n",
        "    bio_temp_te[[\"Avg_Temp_2019_2022\"]],\n",
        "    bio_temp_te[\"count_te_species\"]\n",
        ")\n",
        "\n",
        "# Extract R²\n",
        "r_squared = h14_model['r2'].values[0]\n",
        "\n",
        "# --- Scatter plot with regression line ---\n",
        "plt.figure(figsize=(8,6))\n",
        "sns.regplot(\n",
        "    x=\"Avg_Temp_2019_2022\",\n",
        "    y=\"count_te_species\",\n",
        "    data=bio_temp_te,\n",
        "    color=\"darkred\"\n",
        ")\n",
        "\n",
        "# Annotate R² on the plot\n",
        "plt.text(\n",
        "    x=bio_temp_te[\"Avg_Temp_2019_2022\"].min(),\n",
        "    y=bio_temp_te[\"count_te_species\"].max()*0.9,\n",
        "    s=f\"$R^2$ = {r_squared:.2f}\",\n",
        "    fontsize=12,\n",
        "    color=\"black\"\n",
        ")\n",
        "\n",
        "plt.title(\"H14: Relationship Between Temperature and Threatened/Endangered Species Count\")\n",
        "plt.xlabel(\"Average Temperature (°F, 2019–2022)\")\n",
        "plt.ylabel(\"Threatened/Endangered Species Count\")\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ctLWvc5q5CbW",
      "metadata": {
        "id": "ctLWvc5q5CbW"
      },
      "source": [
        "####Interpretation\n",
        "- The linear regression model shows a significant positive relationship between average temperature (2019–2022) and the number of threatened/endangered species (p = 0.0327). This suggests that as average temperature increases, the count of threatened species tends to rise. The model explains about 20.8% (R² = 0.208) of the variation in species count, indicating that temperature is a meaningful but not sole predictor of endangered species trends."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0YjdzBYMx-JQ",
      "metadata": {
        "id": "0YjdzBYMx-JQ"
      },
      "source": [
        "##Validation Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2IigU6BWyDZc",
      "metadata": {
        "id": "2IigU6BWyDZc"
      },
      "outputs": [],
      "source": [
        "# --- Imports ---\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import r2_score, mean_squared_error\n",
        "\n",
        "# --- Merge Data ---\n",
        "bio_temp_te = bio_climate.merge(count_te_species[[\"State\", \"count_te_species\"]], on=\"State\", how=\"left\")\n",
        "bio_temp_te = bio_temp_te.dropna(subset=[\"Avg_Temp_2019_2022\", \"count_te_species\"])\n",
        "\n",
        "# --- Features & Target ---\n",
        "X = bio_temp_te[[\"Avg_Temp_2019_2022\"]]\n",
        "y = bio_temp_te[\"count_te_species\"]\n",
        "\n",
        "# --- Train/Test Split ---\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
        "\n",
        "# --- Model Training ---\n",
        "model = LinearRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# --- Predictions ---\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# --- Evaluation ---\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "\n",
        "print(f\"Test R²: {r2:.3f}\")\n",
        "print(f\"Mean Squared Error: {mse:.2f}\")\n",
        "print(f\"Model Coefficient (Temp Effect): {model.coef_[0]:.3f}\")\n",
        "print(f\"Intercept: {model.intercept_:.3f}\")\n",
        "\n",
        "# --- Visualization ---\n",
        "plt.figure(figsize=(7,5))\n",
        "sns.regplot(x=y_test, y=y_pred, color=\"darkred\", line_kws={\"color\": \"black\"})\n",
        "plt.xlabel(\"Actual TE Species Count\")\n",
        "plt.ylabel(\"Predicted TE Species Count\")\n",
        "plt.title(\"Final Predictive Model: Temperature → Threatened/Endangered Species Count\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0KPbh9xK0aVj",
      "metadata": {
        "id": "0KPbh9xK0aVj"
      },
      "source": [
        "- The model performed poorly (Test R² = –8.69, MSE = 534.12), indicating that temperature alone is not a reliable predictor of species vulnerability."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4HoA9lre1RTe",
      "metadata": {
        "id": "4HoA9lre1RTe"
      },
      "outputs": [],
      "source": [
        "print(te_species.head(2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ncqyZNHq08YK",
      "metadata": {
        "id": "ncqyZNHq08YK"
      },
      "outputs": [],
      "source": [
        "# --- Imports ---\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# --- Step 1: Merge Species with Parks to Add State ---\n",
        "species_with_state = species.merge(\n",
        "    parks[[\"park name\", \"State\"]],\n",
        "    left_on=\"Park Name\",\n",
        "    right_on=\"park name\",\n",
        "    how=\"left\"\n",
        ")\n",
        "\n",
        "# --- Step 2: Filter Threatened & Endangered Species ---\n",
        "te_species = species_with_state[\n",
        "    species_with_state[\"Conservation Status\"].isin([\"Threatened\", \"Endangered\"])\n",
        "]\n",
        "\n",
        "# --- Step 3: Count Unique Threatened/Endangered Species per State ---\n",
        "te_species_count = (\n",
        "    te_species.groupby(\"State\")[\"Species ID\"]\n",
        "    .nunique()\n",
        "    .reset_index()\n",
        "    .rename(columns={\"Species ID\": \"TE_Species_Count\"})\n",
        ")\n",
        "\n",
        "print(\"✅ Threatened/Endangered species per state:\")\n",
        "print(te_species_count.head(), \"\\n\")\n",
        "\n",
        "# --- Step 4: Filter Weather for Summer Months (June–August, 2019–2021) ---\n",
        "weather_recent = weather_multi[\n",
        "    (weather_multi[\"year\"].between(2019, 2021)) &\n",
        "    (weather_multi[\"month\"].isin([6, 7, 8]))       ###change per season [12, 1, 2] winter; [3, 4, 5] spring; [9, 10, 11] fall)\n",
        "]\n",
        "\n",
        "avg_summer_temp = (\n",
        "    weather_recent.groupby(\"State\")[\"average_temp\"]\n",
        "    .mean()\n",
        "    .reset_index()\n",
        "    .rename(columns={\"average_temp\": \"Avg_Summer_Temp_2019_2021\"})\n",
        ")\n",
        "\n",
        "print(\"✅ Average summer temperatures:\")\n",
        "print(avg_summer_temp.head(), \"\\n\")\n",
        "\n",
        "# --- Step 5: Park Acreage per State ---\n",
        "park_acres = parks.groupby(\"State\")[\"acres\"].sum().reset_index()\n",
        "\n",
        "# --- Step 6: Deforestation — Use Latest Inventory Year ---\n",
        "deforestation_recent = (\n",
        "    deforestation.loc[\n",
        "        deforestation[\"inventory_year\"] == deforestation[\"inventory_year\"].max(),\n",
        "        [\"State\", \"estimate\"]\n",
        "    ]\n",
        "    .rename(columns={\"estimate\": \"Deforestation_Estimate\"})\n",
        ")\n",
        "\n",
        "print(\"✅ Latest deforestation data:\")\n",
        "print(deforestation_recent.head(), \"\\n\")\n",
        "\n",
        "# --- Step 7: Merge All Data Together ---\n",
        "bio_model_data = (\n",
        "    te_species_count\n",
        "    .merge(avg_summer_temp, on=\"State\", how=\"left\")\n",
        "    .merge(park_acres, on=\"State\", how=\"left\")\n",
        "    .merge(deforestation_recent, on=\"State\", how=\"left\")\n",
        ")\n",
        "\n",
        "# Drop any rows missing key variables\n",
        "bio_model_data = bio_model_data.dropna()\n",
        "\n",
        "# --- Step 8: Optional — Normalize Skewed Variables ---\n",
        "bio_model_data[\"log_acres\"] = np.log1p(bio_model_data[\"acres\"])\n",
        "bio_model_data[\"log_deforestation\"] = np.log1p(bio_model_data[\"Deforestation_Estimate\"])\n",
        "\n",
        "print(\"✅ Final merged dataset:\")\n",
        "print(bio_model_data.head())\n",
        "print(f\"\\nFinal dataset shape: {bio_model_data.shape}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "QeJkq5qh2aVG",
      "metadata": {
        "id": "QeJkq5qh2aVG"
      },
      "outputs": [],
      "source": [
        "# --- Regression Modeling ---\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import r2_score, mean_squared_error\n",
        "\n",
        "# Features (predictors) and target\n",
        "X = bio_model_data[[\"Avg_Summer_Temp_2019_2021\", \"log_acres\", \"log_deforestation\"]]\n",
        "y = bio_model_data[\"TE_Species_Count\"]\n",
        "\n",
        "# Fit model\n",
        "model = LinearRegression()\n",
        "model.fit(X, y)\n",
        "\n",
        "# Predictions\n",
        "y_pred = model.predict(X)\n",
        "\n",
        "# Evaluation\n",
        "r2 = r2_score(y, y_pred)\n",
        "mse = mean_squared_error(y, y_pred)\n",
        "\n",
        "print(\"📊 Model Performance\")\n",
        "print(f\"R²: {r2:.3f}\")\n",
        "print(f\"Mean Squared Error: {mse:.2f}\")\n",
        "print(\"\\nCoefficients:\")\n",
        "for var, coef in zip(X.columns, model.coef_):\n",
        "    print(f\"{var}: {coef:.3f}\")\n",
        "print(f\"Intercept: {model.intercept_:.3f}\")\n",
        "\n",
        "# --- Visualization: Actual vs Predicted ---\n",
        "plt.figure(figsize=(7,5))\n",
        "sns.regplot(x=y, y=y_pred, color=\"darkred\", line_kws={\"color\": \"black\"})\n",
        "plt.xlabel(\"Actual TE Species Count\")\n",
        "plt.ylabel(\"Predicted TE Species Count\")\n",
        "plt.title(\"Predicted vs Actual Threatened/Endangered Species\")\n",
        "plt.show()\n",
        "\n",
        "# --- Optional: Pairplot to see relationships ---\n",
        "sns.pairplot(\n",
        "    bio_model_data,\n",
        "    vars=[\"TE_Species_Count\", \"Avg_Summer_Temp_2019_2021\", \"log_acres\", \"log_deforestation\"],\n",
        "    diag_kind=\"kde\",\n",
        "    corner=True\n",
        ")\n",
        "plt.suptitle(\"Variable Relationships Across States\", y=1.02)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "jUol60Dy547o",
      "metadata": {
        "id": "jUol60Dy547o"
      },
      "source": [
        "- Across all seasons, models moderately explained variation in threatened and endangered species counts (R² ≈ 0.50–0.54). Park acreage was the strongest positive predictor, while temperature showed smaller seasonal effects and deforestation remained inconsistent. Summer displayed the weakest fit, and winter the strongest. Train-test validation revealed negative test R² values, indicating limited predictive reliability due to the small sample size. Overall, these models highlight exploratory links between biodiversity, protected land, and seasonal climate variation."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "oiVbx_Y72weG",
      "metadata": {
        "id": "oiVbx_Y72weG"
      },
      "source": [
        "###final validation model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "qIkKCyp42yXL",
      "metadata": {
        "id": "qIkKCyp42yXL"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split data (80% training, 20% testing)\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# Train model\n",
        "model = LinearRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict\n",
        "y_pred_train = model.predict(X_train)\n",
        "y_pred_test = model.predict(X_test)\n",
        "\n",
        "# Evaluate\n",
        "train_r2 = r2_score(y_train, y_pred_train)\n",
        "test_r2 = r2_score(y_test, y_pred_test)\n",
        "train_mse = mean_squared_error(y_train, y_pred_train)\n",
        "test_mse = mean_squared_error(y_test, y_pred_test)\n",
        "\n",
        "print(\"✅ Model Validation Results\")\n",
        "print(f\"Train R²: {train_r2:.3f}\")\n",
        "print(f\"Test R²: {test_r2:.3f}\")\n",
        "print(f\"Train MSE: {train_mse:.2f}\")\n",
        "print(f\"Test MSE: {test_mse:.2f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "THwUhgGb4TV7",
      "metadata": {
        "id": "THwUhgGb4TV7"
      },
      "source": [
        "- The seasonal regression models achieved moderate training fits (R² ≈ 0.63–0.66) but negative testing performance (R² < 0), indicating overfitting and poor generalizability. This suggests that while temperature, deforestation, and protected land area are ecologically relevant, the current data volume and linear model structure are insufficient for reliable prediction. Future models could incorporate larger datasets, additional predictors (e.g., precipitation, habitat type), or nonlinear methods to better capture biodiversity dynamics across seasons."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "KbXFx2Vb3vuJ",
      "metadata": {
        "id": "KbXFx2Vb3vuJ"
      },
      "source": [
        "# Interpretations and Discussion\n",
        "\n",
        "This section explains the results from our statistical analyses and regression models. Each test was used to explore the relationship between deforestation, biodiversity (species richness), and the number of threatened or endangered species across U.S. states. Overall, the results reveal that while there are small trends linking deforestation to biodiversity loss, many of the patterns are weak or not statistically significant, meaning more detailed data would be needed to draw stronger conclusions.\n",
        "1. Chi-Square Tests\n",
        "\n",
        "a. Deforestation Estimates by State\n",
        "The Chi-Square test showed no significant relationship (p > 0.05) between deforestation estimate categories (Low, Medium, High) and individual states.\n",
        "Interpretation: This means that deforestation levels do not differ drastically between states in a statistically meaningful way. Forest loss is a widespread issue rather than being concentrated in specific regions.\n",
        "\n",
        "b. Park Size vs. State\n",
        "The Chi-Square test for park size (classified as 'Large' or 'Small') across states found no significant relationship (p = 0.3915).\n",
        "Interpretation: Large and small parks are evenly distributed nationwide, suggesting that park size depends on geography rather than policy.\n",
        "\n",
        "c. Species Nativeness vs. Category\n",
        "This test showed a highly significant relationship between species nativeness and category (χ² = 30,718.978, p < 0.001).\n",
        "Interpretation: There is a clear association between a species’ category (e.g., Bird, Plant, Mammal) and whether it is native or not. Some groups, like plants and birds, contain proportionally more native species.\n",
        "\n",
        "2. Mann–Whitney U Tests\n",
        "\n",
        "a. Early vs. Late Deforestation Estimates\n",
        "The test comparing early (≤2020) and late (>2020) years showed no significant difference (p ≈ 0.94).\n",
        "Interpretation: Forest area estimates have remained stable over time, indicating consistent deforestation rates.\n",
        "\n",
        "b. High vs. Low Deforestation and Threatened Species\n",
        "The comparison between high and low deforestation states produced a p-value around 0.07.\n",
        "Interpretation: Although not statistically significant, states with higher deforestation tend to have fewer threatened species. This trend may become clearer with more data or over a longer timeframe.\n",
        "\n",
        "c. East vs. West Regions and Species Richness\n",
        "No significant difference was found between eastern and western states.\n",
        "Interpretation: Biodiversity does not differ significantly between regions, implying that nationwide environmental pressures affect both areas similarly.\n",
        "\n",
        "d. Species Richness vs. Deforestation Level\n",
        "The p-value of 0.0698 suggests a weak trend but not a significant difference.\n",
        "Interpretation: Areas with more deforestation may have slightly lower species richness, but stronger evidence is needed.\n",
        "\n",
        "e. Large vs. Small Parks\n",
        "The test found no significant difference in acreage distribution between large and small parks.\n",
        "Interpretation: Park size varies naturally based on geography, not a national pattern.\n",
        "\n",
        "3. Regression and Model Analysis\n",
        "\n",
        "Model 1 — Species Richness vs. Deforestation and Plot Count\n",
        "There is a slight negative relationship between deforestation and species richness. Plot sampling effort was not significant. The model explains very little variation, suggesting other factors like climate and habitat type have stronger effects.\n",
        "\n",
        "Model 2 — Threatened/Endangered Species vs. Deforestation and Plot Count\n",
        "No significant relationships were found. Threatened species numbers likely depend on long-term ecological factors and may lag behind deforestation changes.\n",
        "\n",
        "Model 3 — Species Richness vs. Deforestation, Plot Count, and Year\n",
        "Year was the only significant variable. Species richness decreased by about 296 species per year, showing a strong downward trend. Deforestation and plot count were not significant after controlling for time.\n",
        "\n",
        "Model 4 — Threatened/Endangered Species vs. Deforestation, Plot Count, and Year\n",
        "Threatened species declined by about 2 per year. Deforestation and plot count were not significant, suggesting time is a more dominant factor affecting biodiversity.\n",
        "\n",
        "4. Overall Discussion and Insights\n",
        "Overall, the analyses show weak but consistent trends linking deforestation to biodiversity loss. Although many results were not statistically significant, the direction of the relationships was generally negative, meaning greater deforestation is associated with lower biodiversity.\n",
        "\n",
        "The most consistent predictor across models was time, suggesting that biodiversity is declining steadily each year. This could be due to cumulative factors such as habitat fragmentation, climate change, or pollution. Low R² values in most models indicate that deforestation alone does not explain the complexity of biodiversity changes.\n",
        "\n",
        "Future research should include variables such as land management practices, urbanization, and conservation policies to better understand the full picture of biodiversity loss across the United States.\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}